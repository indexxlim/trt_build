{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28e6e614-e360-4292-965e-0d255027e9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "## Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b88dc1a-a92d-44cc-9fb7-d9e2ef20c8e2",
   "metadata": {},
   "source": [
    "<img src=\"http://developer.download.nvidia.com/compute/machine-learning/frameworks/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Accelerating HuggingFace Whisper Inference with TensorRT\n",
    "\n",
    "Whisper is an encoder-decoder model that converts ASR problems into a speech-to-text format. More specifically, it does so by encoding speech in the input stream. This enables a single model to be trained supervised on a wide variety of Language\n",
    "\n",
    "This notebook shows 3 easy steps to convert a [HuggingFace PyTorch Whisper model](https://huggingface.co/transformers/model_doc/whisper.html) to a TensorRT engine for high-performance inference.\n",
    "\n",
    "1. [Download HuggingFace whisper model](#1)\n",
    "1. [Convert to ONNX format](#2)\n",
    "1. [Convert to TensorRT engine](#3)\n",
    "\n",
    "## Prerequisite\n",
    "\n",
    "Follow the instruction at https://github.com/NVIDIA/TensorRT to build the TensorRT-OSS docker container required to run this notebook.\n",
    "\n",
    "Next, we install some extra dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c36ecb7-c622-4d95-a851-b9a6eb18e81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip3 install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bbdafb",
   "metadata": {},
   "source": [
    "**Note:** After this step, you should restart the Jupyter kernel for the change to take effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "235d2f1b-439e-4cd0-8286-1d63a13f2cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "sys.path.append(ROOT_DIR)\n",
    "\n",
    "import torch\n",
    "import tensorrt as trt\n",
    "\n",
    "# huggingface\n",
    "from transformers import (\n",
    "    WhisperProcessor, \n",
    "    WhisperForConditionalGeneration,\n",
    "    WhisperTokenizer,\n",
    "    WhisperConfig\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4254e2-11fd-4bc7-ac0b-60b1a9e07c4e",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "\n",
    "## 1. Download HuggingFace T5 model and Whisper model\n",
    "\n",
    "First, we download the original HuggingFace PyTorch T5 model from HuggingFace model hubs, together with its associated tokernizer.\n",
    "\n",
    "The T5 variants that are suported by TensorRT 8 are:  t5-small (60M), t5-base (220M), t5-large (770M), t5-3b(3B), t5-11b(11B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b25893a-d9b3-4f40-9dc4-29047c44ac59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "Whisper_VARIANT = \"openai/whisper-large-v2\"    # choices: openai/whisper-tiny | openai/whisper-base | openai/whisper-small | openai/whisper-medium | openai/whisper-large-v2\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(Whisper_VARIANT)\n",
    "whisper_model = WhisperForConditionalGeneration.from_pretrained(Whisper_VARIANT)\n",
    "wh_config = WhisperConfig.from_pretrained(Whisper_VARIANT, use_cache = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f986826-8e46-47b3-87f7-227e6622e1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=processor.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51016f2c-8016-4937-9206-590369c0cb7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81eba99d-8203-4157-8b59-a202db8598b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch Model saved to ./models/openai/whisper-large-v2/pytorch\n"
     ]
    }
   ],
   "source": [
    "# save model locally\n",
    "pytorch_model_dir = './models/{}/pytorch'.format(Whisper_VARIANT)\n",
    "!mkdir -p $pytorch_model_dir\n",
    "\n",
    "whisper_model.save_pretrained(pytorch_model_dir)\n",
    "print(\"Pytorch Model saved to {}\".format(pytorch_model_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed36e6e9-8981-44d9-bff7-649c5d1c64b6",
   "metadata": {},
   "source": [
    "# Encoder output이 다름!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b6bf52b-9cc9-4b27-998b-b58ce4873b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import itertools\n",
    "\n",
    "from typing import BinaryIO, Union\n",
    "\n",
    "import av\n",
    "import numpy as np\n",
    "def decode_audio(\n",
    "    input_file: Union[str, BinaryIO],\n",
    "    sampling_rate: int = 16000,\n",
    "    split_stereo: bool = False,\n",
    "):\n",
    "    \"\"\"Decodes the audio.\n",
    "\n",
    "    Args:\n",
    "      input_file: Path to the input file or a file-like object.\n",
    "      sampling_rate: Resample the audio to this sample rate.\n",
    "      split_stereo: Return separate left and right channels.\n",
    "\n",
    "    Returns:\n",
    "      A float32 Numpy array.\n",
    "\n",
    "      If `split_stereo` is enabled, the function returns a 2-tuple with the\n",
    "      separated left and right channels.\n",
    "    \"\"\"\n",
    "    resampler = av.audio.resampler.AudioResampler(\n",
    "        format=\"s16\",\n",
    "        layout=\"mono\" if not split_stereo else \"stereo\",\n",
    "        rate=sampling_rate,\n",
    "    )\n",
    "\n",
    "    raw_buffer = io.BytesIO()\n",
    "    dtype = None\n",
    "\n",
    "    with av.open(input_file, metadata_errors=\"ignore\") as container:\n",
    "        frames = container.decode(audio=0)\n",
    "        frames = _ignore_invalid_frames(frames)\n",
    "        frames = _group_frames(frames, 500000)\n",
    "        frames = _resample_frames(frames, resampler)\n",
    "\n",
    "        for frame in frames:\n",
    "            array = frame.to_ndarray()\n",
    "            dtype = array.dtype\n",
    "            raw_buffer.write(array)\n",
    "\n",
    "    audio = np.frombuffer(raw_buffer.getbuffer(), dtype=dtype)\n",
    "\n",
    "    # Convert s16 back to f32.\n",
    "    audio = audio.astype(np.float32) / 32768.0\n",
    "\n",
    "    if split_stereo:\n",
    "        left_channel = audio[0::2]\n",
    "        right_channel = audio[1::2]\n",
    "        return left_channel, right_channel\n",
    "\n",
    "    return audio\n",
    "\n",
    "def _ignore_invalid_frames(frames):\n",
    "    iterator = iter(frames)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            yield next(iterator)\n",
    "        except StopIteration:\n",
    "            break\n",
    "        except av.error.InvalidDataError:\n",
    "            continue\n",
    "\n",
    "\n",
    "def _group_frames(frames, num_samples=None):\n",
    "    fifo = av.audio.fifo.AudioFifo()\n",
    "\n",
    "    for frame in frames:\n",
    "        frame.pts = None  # Ignore timestamp check.\n",
    "        fifo.write(frame)\n",
    "\n",
    "        if num_samples is not None and fifo.samples >= num_samples:\n",
    "            yield fifo.read()\n",
    "\n",
    "    if fifo.samples > 0:\n",
    "        yield fifo.read()\n",
    "\n",
    "\n",
    "def _resample_frames(frames, resampler):\n",
    "    # Add None to flush the resampler.\n",
    "    for frame in itertools.chain(frames, [None]):\n",
    "        yield from resampler.resample(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2be0a006-9ee6-45ab-aab1-170c631cf087",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio=decode_audio(\"korean_news.mp4\")\n",
    "duration = audio.shape[0] / 16000\n",
    "inputs = processor(audio, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca242c55-d48f-48e2-a8a3-868e79f3c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs = whisper_model.get_encoder()(inputs['input_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a1fe933-1fea-4d08-9f91-60e3bcd06e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutput(last_hidden_state=tensor([[[-0.3705,  0.0469, -0.2255,  ..., -3.7427, -0.1800,  0.1537],\n",
       "         [-0.3257,  0.2098, -0.0563,  ..., -3.8935,  0.1012,  0.0075],\n",
       "         [-0.0417,  0.3738,  0.3748,  ..., -3.8021,  0.2297, -0.1170],\n",
       "         ...,\n",
       "         [ 0.3712,  0.1128, -0.5410,  ...,  0.4811,  0.7378,  1.6581],\n",
       "         [ 0.4409,  0.5879, -0.0911,  ...,  0.1291, -0.2723,  0.6060],\n",
       "         [ 0.1199,  0.5981,  0.6376,  ..., -0.2903, -0.0964,  0.5309]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3d05d2f-bddf-458b-92ef-9887829f16c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_start_token_id = whisper_model._get_decoder_start_token_id(None, 50258)\n",
    "input_ids  = torch.ones((1, 1), dtype=torch.long, device='cuda') * decoder_start_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f8b0677-6858-49ec-a606-e7da874cf40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whisper_model.get_decoder().max_source_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19c39a60-76e6-48c1-b13d-df5851a19f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"ko\", task=\"transcribe\", no_timestamps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b3769a5-3c7c-4085-95f8-915beba5c02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jisu/miniconda/envs/py38/lib/python3.8/site-packages/transformers/generation_utils.py:1296: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "whisper_model.float().cuda(1)\n",
    "hf_out = whisper_model.generate(inputs['input_features'].cuda(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c0a3b94-5d1d-42c6-b6c1-ea1130a3b053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|startoftranscript|><|ko|><|transcribe|><|notimestamps|> 제6호 태풍 카누는 여전히 매우 강한 세력을 유지한 채 북서지나고 있습니다. 하지만 이동 속도가 점점 느려져 거의 정체하는 모습입니다. 태풍은 동중국해에 머물다 동쪽으로 방향을 급격히 틀어 이동할 걸로 보입니다. 속도도 조금씩 빨라지며 다음 주 초중반에는 일본 규슈 남쪽 해상까지 진출하겠습니다. 세력도 크게 약화하지는 않을 전망입니다.<|endoftext|>']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(hf_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35e698ad-dea2-440f-8239-40e61fefd3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_outputs = whisper_model.model.decoder(input_ids=input_ids.cuda(1), encoder_hidden_states=encoder_outputs['last_hidden_state'].cuda(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b297957-91d2-42e6-b8d0-6b79a9f9e31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_output = whisper_model.proj_out(decoder_outputs.last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5bab17-d6ad-435f-86c0-2a231c737d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e747f8d-9d47-4ab2-9d98-8be9dfdddad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b771df-15ad-4499-bdb4-6434cc17df28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1b53f86-1f78-4946-a4fc-6d93cc6764f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # legacy: users may modify the model configuration to control generation -- update the generation config\n",
    "# # model attribute accordingly, if it was created from the model config\n",
    "# if self.generation_config._from_model_config:\n",
    "#     new_generation_config = GenerationConfig.from_model_config(self.config)\n",
    "#     if new_generation_config != self.generation_config:\n",
    "#         warnings.warn(\n",
    "#             \"You have modified the pretrained model configuration to control generation. This is a\"\n",
    "#             \" deprecated strategy to control generation and will be removed soon, in a future version.\"\n",
    "#             \" Please use a generation configuration file (see\"\n",
    "#             \" https://huggingface.co/docs/transformers/main_classes/text_generation )\"\n",
    "#         )\n",
    "#         self.generation_config = new_generation_config\n",
    "# generation_config = self.generation_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c389c1d2-b900-4fcd-99db-81b6426a5469",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.generation_logits_process import (\n",
    "    NoRepeatNGramLogitsProcessor,\n",
    "    MinLengthLogitsProcessor,\n",
    "    LogitsProcessorList,\n",
    "    SuppressTokensAtBeginLogitsProcessor,\n",
    "    SuppressTokensLogitsProcessor,\n",
    "    ForceTokensLogitsProcessor,\n",
    ")\n",
    "\n",
    "from transformers.generation_stopping_criteria import (\n",
    "    MaxLengthCriteria,\n",
    "    StoppingCriteriaList,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ed1e396-00ca-4efc-80d3-868f66a8d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"ko\", task=\"transcribe\", no_timestamps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a422bf6a-63da-4014-8e67-c8f45f93df5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_token_id = tokenizer.bos_token_id\n",
    "num_beams = whisper_model.config.num_beams\n",
    "length_penalty = whisper_model.config.length_penalty\n",
    "early_stopping = whisper_model.config.early_stopping\n",
    "num_beam_groups = whisper_model.config.num_beam_groups\n",
    "do_sample = whisper_model.config.do_sample\n",
    "num_return_sequences = whisper_model.config.num_return_sequences\n",
    "pad_token_id = tokenizer.pad_token_id\n",
    "eos_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74f4804-b95a-45d8-8c5b-3ff6681a12a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e596cc6a-030d-4fe0-a62f-c76db390eabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs_tensor, model_input_name, model_kwargs = whisper_model._prepare_model_inputs(inputs, bos_token_id, model_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3b08146-5419-4357-8965-1f76d54489bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopping_criteria = whisper_model._get_stopping_criteria(\n",
    "    max_length=whisper_model.config.max_length, max_time=None, stopping_criteria=StoppingCriteriaList()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f2c7b33-1d17-451b-9fb6-5df1d189ff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_seq_length = input_ids.shape[-1]\n",
    "\n",
    "\n",
    "begin_index = input_ids_seq_length\n",
    "begin_index = begin_index if (input_ids_seq_length > 1 or whisper_model.config.forced_bos_token_id is None) else begin_index + 1\n",
    "if whisper_model.config.forced_bos_token_id is not None:\n",
    "    begin_index += whisper_model.config.forced_bos_token_id[-1][0]  # generation starts after the last token that is forced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de7195ed-b914-4938-a8af-539821c44f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_processor = LogitsProcessorList([\n",
    "    SuppressTokensLogitsProcessor(whisper_model.config.suppress_tokens),\n",
    "    SuppressTokensAtBeginLogitsProcessor(whisper_model.config.begin_suppress_tokens, begin_index), \n",
    "    ForceTokensLogitsProcessor (processor.get_decoder_prompt_ids(language=\"ko\", task=\"transcribe\", no_timestamps=True))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66c48dd7-0b7d-4abb-b859-17fa504ec334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.66 s, sys: 268 ms, total: 6.93 s\n",
      "Wall time: 6.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# greedy_search(\n",
    "#     input_ids,\n",
    "#     logits_processor=logits_processor,\n",
    "#     stopping_criteria=stopping_criteria,\n",
    "#     pad_token_id=pad_token_id,\n",
    "#     eos_token_id=eos_token_id,\n",
    "#     output_scores=output_scores,\n",
    "#     return_dict_in_generate=return_dict_in_generate,\n",
    "#     synced_gpus=synced_gpus,\n",
    "#     **model_kwargs,\n",
    "# )\n",
    "decoder_output = whisper_model.greedy_search(\n",
    "    input_ids=input_ids.cuda(1),\n",
    "    encoder_outputs=encoder_outputs.last_hidden_state.cuda(1),\n",
    "   # stopping_criteria=stopping_criteria,\n",
    "    logits_processor=logits_processor,\n",
    "    stopping_criteria=stopping_criteria,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    use_cache=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7683ae0-f5bb-4ad2-8154-a8aefec1f9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|startoftranscript|><|ko|><|transcribe|><|notimestamps|> 제6호 태풍 카누는 여전히 매우 강한 세력을 유지한 채 북서지나고 있습니다. 하지만 이동 속도가 점점 느려져 거의 정체하는 모습입니다. 태풍은 동중국해에 머물다 동쪽으로 방향을 급격히 틀어 이동할 걸로 보입니다. 속도도 조금씩 빨라지며 다음 주 초중반에는 일본 규슈 남쪽 해상까지 진출하겠습니다. 세력도 크게 약화하지는 않을 전망입니다.<|endoftext|>']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "622c3d7c-5f63-47a9-b4f8-19ed821501f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|startoftranscript|><|ko|><|transcribe|><|notimestamps|> 제6호 태풍 카누는 여전히 매우 강한 세력을 유지한 채 북서지나고 있습니다. 하지만 이동 속도가 점점 느려져 거의 정체하는 모습입니다. 태풍은 동중국해에 머물다 동쪽으로 방향을 급격히 틀어 이동할 걸로 보입니다. 속도도 조금씩 빨라지며 다음 주 초중반에는 일본 규슈 남쪽 해상까지 진출하겠습니다. 세력도 크게 약화하지는 않을 전망입니다.<|endoftext|>']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.batch_decode(hf_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1c3ad8-e39f-4725-9627-26ee23f8bacf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11ea023d-c4d4-43bb-9d77-c76684e0b06f",
   "metadata": {},
   "source": [
    "### Inference with PyTorch model\n",
    "\n",
    "Next, we will carry out inference with the PyTorch model.\n",
    "\n",
    "#### Single example inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9c2c472-20d3-4f32-8032-a5fcb5bd4bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset librispeech_asr_dummy (/home/jisu/.cache/huggingface/datasets/hf-internal-testing___librispeech_asr_dummy/clean/2.1.0/d3bc4c2bc2078fcde3ad0f0f635862e4c0fef78ba94c4a34c4c250a097af240b)\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "\n",
    "audio_inputs = processor(ds[0][\"audio\"][\"array\"], return_tensors=\"pt\")\n",
    "input_features = audio_inputs.input_features\n",
    "\n",
    "# WAR: Using an ugly representation because cuda 11.4 does not support GPU models due to cublas errors\n",
    "if \"LD_LIBRARY_PATH\" in os.environ and \"cuda-11.4\" in os.environ[\"LD_LIBRARY_PATH\"]:\n",
    "    whisper_model = whisper_model.cpu()\n",
    "    input_features = input_features.to('cpu')\n",
    "else:\n",
    "    whisper_model = whisper_model.cuda()\n",
    "    input_features = input_features.to('cuda:1')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d194b4bd-5137-49a9-b351-c56caf2266d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_features = inputs['input_features'].cuda(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "203ac7cc-ee7e-4def-9462-4e17ca6fae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"en\", task=\"transcribe\", no_timestamps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1f4eaa3-968c-4841-80d9-8692e01c93ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jisu/miniconda/envs/py38/lib/python3.8/site-packages/transformers/generation_utils.py:1296: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whisper_model.cuda(1)\n",
    "with torch.no_grad():\n",
    "    generated_ids = whisper_model.generate(inputs=input_features)\n",
    "\n",
    "transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "transcription\n",
    "# ' Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2634d56-0118-4240-9fa5-331419bc4ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "667fcacc-02cb-415d-a9ff-2d2ec44ef225",
   "metadata": {},
   "source": [
    "#### Model inference benchmark: encoder and decoder stacks\n",
    "\n",
    "For benchmarking purposes, we will employ a helper functions `encoder_inference` and `decoder_inference` which execute the inference repeatedly for the T5 encoder and decoder stacks separately, and measure end to end execution time. Let's take note of this execution time for comparison with TensorRT. \n",
    " \n",
    "`TimingProfile` is a named tuple that specifies the number of experiments and number of times to call the function per iteration (and number of warm-up calls although it is not used here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "596ea542-d9e5-4367-b643-d60027fa05e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Whisper.measurements import decoder_inference as w_decoder_inference, encoder_inference as w_encoder_inference, full_inference as w_full_inference, full_inference_greedy, full_inference_beam\n",
    "from Whisper.export import WhisperEncoderTorchFile, WhisperDecoderTorchFile, WhisperEncoderTRTEngine, WhisperDecoderTRTEngine\n",
    "\n",
    "from NNDF.networks import TimingProfile\n",
    "from NNDF.torch_utils import expand_inputs_for_beam_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1e38c03-23d6-4e53-b0f5-758e205a235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_torch_encoder = WhisperEncoderTorchFile.TorchModule(whisper_model.model.encoder)\n",
    "whisper_torch_decoder = WhisperDecoderTorchFile.TorchModule(\n",
    "    whisper_model.model.decoder, whisper_model.proj_out, whisper_model.config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9339f413-3b22-4c0d-a49a-e81b05e1105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = whisper_model.generate(inputs=input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1337ba74-07be-4179-8804-30de41fb899d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.02 s, sys: 1.07 s, total: 3.09 s\n",
      "Wall time: 3.09 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.18660088896285743"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "input_features = input_features\n",
    "\n",
    "encoder_last_hidden_state, encoder_e2e_median_time = w_encoder_inference(\n",
    "    whisper_torch_encoder, input_features, TimingProfile(iterations=10, number=1, warmup=1, duration=0, percentile=50)\n",
    ")\n",
    "encoder_e2e_median_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3324cf43-0a3f-4a48-8fc9-e0eeed63c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([[1, 1]]) * whisper_model.config.decoder_start_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db4a1cf7-4ed3-47da-b223-2ff7579f676e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 709 ms, sys: 90.8 ms, total: 800 ms\n",
      "Wall time: 800 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03334461199119687"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "decoder_output, decoder_e2e_median_time = w_decoder_inference(\n",
    "    whisper_torch_decoder, input_ids.cuda(), encoder_last_hidden_state, TimingProfile(iterations=10, number=1, warmup=1, duration=0, percentile=50)\n",
    ")\n",
    "decoder_e2e_median_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99d5a06-a8f5-4ce7-a34c-bc42f07ac706",
   "metadata": {},
   "source": [
    "#### Full model inference and benchmark\n",
    "\n",
    "Next, we will try the T5 model for the task of translation from English to German.\n",
    "\n",
    "For benchmarking purposes, we will employ a helper function `full_inference` which executes the inference repeatedly and measures end to end execution time. Let's take note of this execution time for comparison with TensorRT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d0d0bdde-a285-40e5-a554-4e1b35f39b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Whisper.WhisperModelConfig import WhisperModelTRTConfig, WhisperMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2fc88907-7d1f-4453-8863-5425f7ddc7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e5ac34d4-efd4-46b0-a142-397b7bbe6a63",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_beams = 1\n",
    "min_output_len =0 \n",
    "max_output_len = whisper_model.config.max_length\n",
    "tokenizer = processor.tokenizer\n",
    "forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"en\", task=\"transcribe\", no_timestamps=True)\n",
    "whisper_model.config.forced_decoder_ids = forced_decoder_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3410dbdc-91a4-48c8-8acf-b13b51358689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NNDF.general_utils import measure_python_inference_code\n",
    "timing_profile = TimingProfile(iterations=10, number=1, warmup=1, duration=0, percentile=[50,99])\n",
    "\n",
    "def percentile_print(timing):\n",
    "    return ', '.join(['p{} {:.2f}ms'.format(timing_profile.percentile[i], p*1000) for i,p in enumerate(timing)])\n",
    "whisper_model = WhisperForConditionalGeneration.from_pretrained(Whisper_VARIANT).cuda(1)\n",
    "whisper_model.config.forced_decoder_ids = forced_decoder_ids\n",
    "# encoder-decoder inference \n",
    "with torch.no_grad():\n",
    "    output_ids = whisper_model.generate(input_features, max_length=max_output_len, min_length=min_output_len, num_beams=num_beams, use_cache=False)\n",
    "    outputs = processor.tokenizer.decode(output_ids[-1,:], skip_special_tokens=True)\n",
    "outputs_hf = outputs\n",
    "\n",
    "# timing\n",
    "# FP32\n",
    "whisper_model.float()\n",
    "hf_nonkv_time = measure_python_inference_code(lambda: whisper_model.generate(input_features, max_length=max_output_len, min_length=min_output_len, num_beams=num_beams, use_cache=False), timing_profile)\n",
    "hf_kv_time = measure_python_inference_code(lambda: whisper_model.generate(input_features, max_length=max_output_len, min_length=min_output_len, num_beams=num_beams, use_cache=True), timing_profile)\n",
    "\n",
    "# FP16, cuda 11.4 has cublas error that will fail in both cpu or cpu model for Whisper\n",
    "# if not cuda_114_mode:\n",
    "whisper_model= whisper_model.half()\n",
    "hf_nonkv_time_fp16 = measure_python_inference_code(lambda: whisper_model.generate(input_features.half(), max_length=max_output_len, min_length=min_output_len, num_beams=num_beams, use_cache=False), timing_profile)\n",
    "hf_kv_time_fp16 = measure_python_inference_code(lambda: whisper_model.generate(input_features.half(), max_length=max_output_len, min_length=min_output_len, num_beams=num_beams, use_cache=True), timing_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08a80940-4ff5-40d4-a82f-35a5cc1de908",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FP32\n",
    "HF_KV=True\n",
    "timing_profile = TimingProfile(iterations=10, number=1, warmup=1, duration=0, percentile=[50,99])\n",
    "whisper_model.float()\n",
    "input_features =input_features.float()\n",
    "whisper_torch_encoder = WhisperEncoderTorchFile.TorchModule(whisper_model.get_encoder())\n",
    "whisper_torch_decoder = WhisperDecoderTorchFile.TorchModule(whisper_model.get_decoder(), whisper_model.proj_out, whisper_model.config)\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoder_last_hidden_state, encoder_pytorch_time = w_encoder_inference(whisper_torch_encoder, input_features, timing_profile)\n",
    "    _, decoder_pytorch_time = w_decoder_inference(whisper_torch_decoder, expand_inputs_for_beam_search(input_ids, num_beams) if num_beams > 1 else input_ids, expand_inputs_for_beam_search(encoder_last_hidden_state, num_beams) if num_beams > 1 else encoder_last_hidden_state, timing_profile, use_cache=HF_KV)\n",
    "    if num_beams == 1:\n",
    "        output_ids, full_pytorch_time = full_inference_greedy(whisper_torch_encoder,whisper_torch_decoder,input_features,tokenizer,timing_profile,max_length=max_output_len, min_length=min_output_len, use_cache=HF_KV, forced_decoder_ids=forced_decoder_ids)\n",
    "    else:\n",
    "        output_ids, full_pytorch_time = full_inference_beam(whisper_torch_encoder,whisper_torch_decoder,input_features,tokenizer,timing_profile,num_beams=num_beams,max_length=max_output_len, min_length=min_output_len, use_cache=HF_KV, forced_decoder_ids=forced_decoder_ids)\n",
    "    outputs = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "outputs_pytorch = outputs\n",
    "\n",
    "# # FP16\n",
    "# if not cuda_114_mode:\n",
    "whisper_model.half()\n",
    "input_features= input_features.half()\n",
    "whisper_torch_encoder_fp16 = WhisperEncoderTorchFile.TorchModule(whisper_model.get_encoder())\n",
    "whisper_torch_decoder_fp16 = WhisperDecoderTorchFile.TorchModule(whisper_model.get_decoder(), whisper_model.proj_out, whisper_model.config)\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoder_last_hidden_state, encoder_pytorch_time_fp16 = w_encoder_inference(whisper_torch_encoder_fp16, input_features, timing_profile)\n",
    "    _, decoder_pytorch_time_fp16 = w_decoder_inference(whisper_torch_decoder_fp16, expand_inputs_for_beam_search(input_ids, num_beams) if num_beams > 1 else input_ids, expand_inputs_for_beam_search(encoder_last_hidden_state, num_beams) if num_beams > 1 else encoder_last_hidden_state, timing_profile, use_cache=HF_KV)\n",
    "    if num_beams == 1:\n",
    "        output_ids_fp16, full_pytorch_time_fp16 = full_inference_greedy(whisper_torch_encoder_fp16,whisper_torch_decoder_fp16,input_features,tokenizer,timing_profile,max_length=max_output_len, min_length=min_output_len, use_cache=HF_KV, forced_decoder_ids=forced_decoder_ids)\n",
    "    else:\n",
    "        output_ids_fp16, full_pytorch_time_fp16 = full_inference_beam(whisper_torch_encoder_fp16,whisper_torch_decoder_fp16,input_features,tokenizer,timing_profile,num_beams=num_beams,max_length=max_output_len, min_length=min_output_len, use_cache=HF_KV, forced_decoder_ids=forced_decoder_ids)\n",
    "    outputs_fp16 = tokenizer.decode(output_ids_fp16[0], skip_special_tokens=True)    \n",
    "\n",
    "outputs_pytorch_fp16 = outputs_fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "59fcf316-01a7-44e2-b18b-1fde97aab990",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decoder_input_ids = torch.full(\n",
    "    (1, 1),\n",
    "    whisper_torch_decoder.config.decoder_start_token_id,\n",
    "    dtype=torch.int32,\n",
    ")\n",
    "if forced_decoder_ids is None:\n",
    "    forced_decoder_ids = whisper_torch_decoder.config.forced_decoder_ids\n",
    "\n",
    "stopping_criteria = StoppingCriteriaList([MaxLengthCriteria(224)])\n",
    "logits_processor = LogitsProcessorList(\n",
    "    [\n",
    "        SuppressTokensLogitsProcessor(whisper_torch_decoder.config.suppress_tokens),\n",
    "        SuppressTokensAtBeginLogitsProcessor(\n",
    "            whisper_torch_decoder.config.begin_suppress_tokens,\n",
    "            decoder_input_ids.shape[-1],\n",
    "        ),\n",
    "        ForceTokensLogitsProcessor(forced_decoder_ids),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "decoder_input_ids = decoder_input_ids.to(\"cuda\")\n",
    "\n",
    "def _e2e():\n",
    "    with torch.no_grad():\n",
    "        encoder_last_hidden_state = whisper_torch_encoder(input_features=input_features)\n",
    "        decoder_output_greedy = whisper_torch_decoder.greedy_search(\n",
    "            input_ids=decoder_input_ids,\n",
    "            encoder_hidden_states=encoder_last_hidden_state,\n",
    "            stopping_criteria=stopping_criteria,\n",
    "            logits_processor=logits_processor,\n",
    "            use_cache=use_cache,\n",
    "        )\n",
    "    return decoder_output_greedy\n",
    "\n",
    "# With e2e we can opt to bind inputs only once for hidden states for optimization\n",
    "def _e2e_trt():\n",
    "    with torch.no_grad():\n",
    "        encoder_last_hidden_state = whisper_torch_encoder(input_features=input_features)\n",
    "        whisper_torch_decoder.set_encoder_hidden_states_for_inference_cycle(\n",
    "            encoder_last_hidden_state\n",
    "        )\n",
    "        decoder_output_greedy = whisper_torch_decoder.greedy_search(\n",
    "            input_ids=decoder_input_ids,\n",
    "            encoder_hidden_states=encoder_last_hidden_state,\n",
    "            stopping_criteria=stopping_criteria,\n",
    "            logits_processor=logits_processor,\n",
    "            use_cache=use_cache,\n",
    "        )\n",
    "    return decoder_output_greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "989f32e5-6ca9-4609-b5f7-d300a3919f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch FP32 Output identical to HF results? True\n",
      "PyTorch FP16 Output identical to HF results? True\n",
      "\n",
      "\n",
      "Device: NVIDIA A100-SXM4-80GB\n",
      "Precision: FP32, Number of Beams: 1\n",
      "Encoder time: [0.18671592697501183, 0.22230989392846823]\n",
      "Decoder time: [0.031467140070162714, 0.03270867792889476]\n",
      "Full E2E time: [0.6680863999063149, 0.669867079006508]\n",
      "Precision: FP16, Number of Beams: 1\n",
      "Encoder time: [0.046387549955397844, 0.04661275597754866]\n",
      "Decoder time: [0.027844374999403954, 0.04649727907963097]\n",
      "Full E2E time: [0.5367980289738625, 0.5557327539427206]\n"
     ]
    }
   ],
   "source": [
    "# print\n",
    "print(f'PyTorch FP32 Output identical to HF results? {outputs_pytorch == outputs_hf}')\n",
    "print(f'PyTorch FP16 Output identical to HF results? {outputs_pytorch_fp16 == outputs_hf}')\n",
    "print('\\n')      \n",
    "print(f'Device: {torch.cuda.get_device_name()}')\n",
    "print(f\"Precision: FP32, Number of Beams: {num_beams}\")\n",
    "print(f\"Encoder time: {encoder_pytorch_time}\")\n",
    "print(f\"Decoder time: {decoder_pytorch_time}\")\n",
    "print(f\"Full E2E time: {full_pytorch_time}\")\n",
    "print(f\"Precision: FP16, Number of Beams: {num_beams}\")\n",
    "print(f\"Encoder time: {encoder_pytorch_time_fp16}\")\n",
    "print(f\"Decoder time: {decoder_pytorch_time_fp16}\")\n",
    "print(f\"Full E2E time: {full_pytorch_time_fp16}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d662701-e430-4fdc-ad46-1f296defcf8f",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "\n",
    "## 2. Convert to ONNX\n",
    "\n",
    "Prior to converting the model to a TensorRT engine, we will first convert the PyTorch model to an intermediate universal format.\n",
    "\n",
    "ONNX is an open format for machine learning and deep learning models. It allows you to convert deep learning and machine learning models from different frameworks such as TensorFlow, PyTorch, MATLAB, Caffe, and Keras to a single format.\n",
    "\n",
    "The steps to convert a PyTorch model to TensorRT are as follows:\n",
    "- Convert the pretrained image segmentation PyTorch model into ONNX.\n",
    "- Import the ONNX model into TensorRT.\n",
    "- Apply optimizations and generate an engine.\n",
    "- Perform inference on the GPU. \n",
    "\n",
    "For the Whisper model, we will convert the encoder and decoder seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8b1fd7ce-d39b-4142-9a05-647143518d6f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jisu/miniconda/envs/py38/lib/python3.8/site-packages/transformers/models/whisper/modeling_whisper.py:198: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_weights.size() != (bsz * self.num_heads, tgt_len, src_len):\n",
      "/home/jisu/miniconda/envs/py38/lib/python3.8/site-packages/transformers/models/whisper/modeling_whisper.py:237: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_output.size() != (bsz * self.num_heads, tgt_len, self.head_dim):\n",
      "/home/jisu/miniconda/envs/py38/lib/python3.8/site-packages/transformers/models/whisper/modeling_whisper.py:742: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if input_shape[-1] > 1:\n",
      "/home/jisu/miniconda/envs/py38/lib/python3.8/site-packages/transformers/models/whisper/modeling_whisper.py:72: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  mask = torch.full((tgt_len, tgt_len), torch.tensor(torch.finfo(dtype).min))\n",
      "/home/jisu/miniconda/envs/py38/lib/python3.8/site-packages/transformers/models/whisper/modeling_whisper.py:205: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attention_mask.size() != (bsz, 1, tgt_len, src_len):\n"
     ]
    }
   ],
   "source": [
    "from NNDF.networks import NetworkMetadata, Precision\n",
    "TRT_KV = False\n",
    "\n",
    "wh_onnx_model_path = './models/{}/onnx'.format(Whisper_VARIANT)\n",
    "!mkdir -p $wh_onnx_model_path\n",
    "\n",
    "# FP32\n",
    "whisper_model.float()\n",
    "metadata = NetworkMetadata(variant=Whisper_VARIANT, precision=Precision(fp16=False), other=WhisperMetadata(kv_cache=TRT_KV))\n",
    "trt_config = WhisperModelTRTConfig()\n",
    "metadata_string = trt_config.get_metadata_string(metadata)\n",
    "\n",
    "wh_encoder_onnx_model_fpath = metadata_string + \"-encoder.onnx\"\n",
    "wh_decoder_onnx_model_fpath = metadata_string + \"-decoder-with-lm-head.onnx\"\n",
    "\n",
    "# for onnx conversion, ensure model is on CPU and FP32 precision in this step\n",
    "whisper_torchfile_encoder = WhisperEncoderTorchFile(whisper_model.to('cpu'), metadata)\n",
    "whisper_torchfile_decoder = WhisperDecoderTorchFile(whisper_model.to('cpu'), metadata)\n",
    "\n",
    "onnx_whisper_encoder = whisper_torchfile_encoder.as_onnx_model(os.path.join(wh_onnx_model_path, wh_encoder_onnx_model_fpath), force_overwrite=True)\n",
    "onnx_whisper_decoder = whisper_torchfile_decoder.as_onnx_model(os.path.join(wh_onnx_model_path, wh_decoder_onnx_model_fpath), force_overwrite=True)\n",
    "\n",
    "# FP16\n",
    "metadata_fp16 = NetworkMetadata(variant=Whisper_VARIANT, precision=Precision(fp16=True), other=WhisperMetadata(kv_cache=TRT_KV))\n",
    "trt_config_fp16 = WhisperModelTRTConfig()\n",
    "metadata_string_fp16 = trt_config_fp16.get_metadata_string(metadata_fp16)\n",
    "\n",
    "wh_encoder_onnx_model_fpath_fp16 = metadata_string_fp16 + \"-encoder.onnx\"\n",
    "wh_decoder_onnx_model_fpath_fp16 = metadata_string_fp16 + \"-decoder-with-lm-head.onnx\"\n",
    "\n",
    "# for onnx conversion, ensure model is on CPU and FP32 precision in this step\n",
    "whisper_torchfile_encoder = WhisperEncoderTorchFile(whisper_model.to('cpu'), metadata)\n",
    "whisper_torchfile_decoder = WhisperDecoderTorchFile(whisper_model.to('cpu'), metadata)\n",
    "\n",
    "onnx_whisper_encoder_fp16 = whisper_torchfile_encoder.as_onnx_model(os.path.join(wh_onnx_model_path, wh_encoder_onnx_model_fpath_fp16), force_overwrite=True)\n",
    "onnx_whisper_decoder_fp16 = whisper_torchfile_decoder.as_onnx_model(os.path.join(wh_onnx_model_path, wh_decoder_onnx_model_fpath_fp16), force_overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baf007e-5508-485c-a87f-9bfe16260452",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "\n",
    "## 3. Convert to TensorRT\n",
    "\n",
    "Now we are ready to parse the ONNX encoder and decoder models and convert them to optimized TensorRT engines.\n",
    "\n",
    "Since the models contains dynamic input shapes, we can specify a valid input range with a TensorRT optimization profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "037ac958-2627-439c-9db5-27640e3f7967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Whisper.export import WhisperDecoderONNXFile, WhisperEncoderONNXFile\n",
    "from polygraphy.backend.trt import Profile\n",
    "from tensorrt import PreviewFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cfb64120-9012-40c8-b1e2-4a6366b71294",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_hidden_size = whisper_model.config.d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7fb269a5-9753-4c1a-9f4a-036552ff643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_beams=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "572b2d68-4004-4724-abd4-079c5487e345",
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_tensorrt_model_path = './models/{}/tensorrt'.format(Whisper_VARIANT)\n",
    "!mkdir -p wh_tensorrt_model_path\n",
    "# Decoder optimization profiles\n",
    "batch_size = 1\n",
    "max_sequence_length = WhisperModelTRTConfig.MAX_SEQUENCE_LENGTH[Whisper_VARIANT]\n",
    "decoder_profile = Profile()\n",
    "decoder_profile.add(\n",
    "    \"input_ids\",\n",
    "    min=(batch_size * num_beams, 1),\n",
    "    opt=(batch_size * num_beams, max_sequence_length // 2),\n",
    "    max=(batch_size * num_beams, max_sequence_length),\n",
    ")\n",
    "decoder_profile.add(\n",
    "    \"encoder_hidden_states\",\n",
    "    min=(batch_size * num_beams, 1, encoder_hidden_size),\n",
    "    opt=(batch_size * num_beams, 1500, encoder_hidden_size),\n",
    "    max=(batch_size * num_beams, 1500, encoder_hidden_size),\n",
    ")\n",
    "\n",
    "# Encoder optimization profiles\n",
    "encoder_profile = Profile()\n",
    "encoder_profile.add(\n",
    "    \"input_features\",\n",
    "    min=(batch_size, 80, 3000),\n",
    "    opt=(batch_size, 80, 3000),\n",
    "    max=(batch_size, 80, 3000)\n",
    ")\n",
    "\n",
    "disable_preview_dynamic_shapes = False\n",
    "engine_tag = f\"bs{batch_size}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baae019-fee7-4c34-b91f-1cb198f451f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ed23ccb-17db-4f7b-b8f4-7fbf5502c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "force_write=False\n",
    "engine_tag = f\"bs{batch_size}\"\n",
    "\n",
    "if num_beams > 1:\n",
    "    engine_tag += \"-beam{}\".format(num_beams)\n",
    "\n",
    "preview_features = [PreviewFeature.DISABLE_EXTERNAL_TACTIC_SOURCES_FOR_CORE_0805]\n",
    "if disable_preview_dynamic_shapes:\n",
    "    engine_tag += \"-noPreviewFasterDynamicShapes\"\n",
    "else:\n",
    "    preview_features.append(PreviewFeature.FASTER_DYNAMIC_SHAPES_0805)\n",
    "\n",
    "# FP32\n",
    "wh_encoder_engine_name = os.path.join(wh_tensorrt_model_path, wh_encoder_onnx_model_fpath) + f\"-{engine_tag}.engine\".replace(f\"-beam{num_beams}\", \"\") # encoder engine not affected by beam search\n",
    "wh_decoder_engine_name = os.path.join(wh_tensorrt_model_path, wh_decoder_onnx_model_fpath) + f\"-{engine_tag}.engine\"\n",
    "\n",
    "if not os.path.exists(wh_encoder_engine_name) or force_write:\n",
    "    whisper_trt_encoder_engine = WhisperEncoderONNXFile(os.path.join(wh_onnx_model_path, wh_encoder_onnx_model_fpath), metadata).as_trt_engine(\n",
    "        wh_encoder_engine_name, \n",
    "        force_overwrite=force_write,\n",
    "        profiles=[encoder_profile], \n",
    "        preview_features=preview_features\n",
    "    )\n",
    "else:\n",
    "    whisper_trt_encoder_engine = WhisperEncoderTRTEngine(wh_encoder_engine_name, metadata)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "829a0556-c84b-4e96-a794-b0ef768bf6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Whisper.trt import WhisperTRTEncoder, WhisperTRTDecoder, TRTHFRunner\n",
    "from transformers import WhisperConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5d46cf1e-124d-46ff-99b3-74c99d9fca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_config = WhisperConfig.from_pretrained(Whisper_VARIANT, use_cache = metadata.other.kv_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "430ae801-234f-4b1a-b9dc-103119cf621c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09/06/2023-10:09:38] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n"
     ]
    }
   ],
   "source": [
    "whisper_trt_encoder = WhisperTRTEncoder(whisper_trt_encoder_engine, metadata, trt_config, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4e883c9f-dcf2-4800-a808-7a9f67aa892a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 14.5 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3555, -0.4582, -0.3098,  ..., -3.4159, -0.5448,  0.0769],\n",
       "         [ 0.0394, -0.2632,  0.2806,  ..., -3.0623, -0.5295,  0.1974],\n",
       "         [ 0.7707, -0.2223,  0.6847,  ..., -2.1922, -0.2827, -0.0169],\n",
       "         ...,\n",
       "         [ 0.5559,  0.1904, -0.0888,  ..., -0.9813, -0.1762, -0.6617],\n",
       "         [ 0.2957,  0.3258, -0.5251,  ..., -0.5859, -0.5897, -0.5441],\n",
       "         [-0.0442,  0.6663, -0.8131,  ..., -0.1867, -0.7591, -0.5466]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "whisper_trt_encoder(input_features=inputs['input_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "31b1bcc8-ed43-4ef2-a66f-9a1b7ade40ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3700,  0.0478, -0.2257,  ..., -3.7430, -0.1793,  0.1543],\n",
       "         [-0.3259,  0.2111, -0.0563,  ..., -3.8932,  0.1018,  0.0082],\n",
       "         [-0.0418,  0.3745,  0.3751,  ..., -3.8022,  0.2305, -0.1163],\n",
       "         ...,\n",
       "         [ 0.3711,  0.1129, -0.5408,  ...,  0.4810,  0.7379,  1.6578],\n",
       "         [ 0.4409,  0.5879, -0.0910,  ...,  0.1290, -0.2721,  0.6057],\n",
       "         [ 0.1196,  0.5980,  0.6380,  ..., -0.2902, -0.0962,  0.5307]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whisper_torch_encoder.cuda()\n",
    "whisper_torch_encoder(input_features=inputs['input_features'].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3249d071-711d-4c29-9aa3-c6d08dc2110c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9514a333-83eb-4654-b74c-4586a91ec7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;11m[W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\u001b[0m\n",
      "\u001b[38;5;11m[W] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\u001b[0m\n",
      "\u001b[38;5;11m[W] It looks like some layers in the network have compute precision set, but precision constraints were not enabled. \n",
      "    Precision constraints must be set to 'prefer' or 'obey' for layer compute precision to take effect. \n",
      "    Note: Layers and their requested precisions were: {'encoder/layers.0/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.0/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.0/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.0/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.0/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.0/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.0/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.0/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.0/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.0/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.0/final_layer_norm/Add': 'FLOAT', 'encoder/layers.0/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.0/final_layer_norm/Div': 'FLOAT', 'encoder/layers.0/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.1/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.1/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.1/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.1/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.1/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.1/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.1/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.1/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.1/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.1/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.1/final_layer_norm/Add': 'FLOAT', 'encoder/layers.1/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.1/final_layer_norm/Div': 'FLOAT', 'encoder/layers.1/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.2/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.2/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.2/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.2/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.2/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.2/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.2/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.2/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.2/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.2/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.2/final_layer_norm/Add': 'FLOAT', 'encoder/layers.2/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.2/final_layer_norm/Div': 'FLOAT', 'encoder/layers.2/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.3/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.3/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.3/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.3/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.3/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.3/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.3/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.3/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.3/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.3/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.3/final_layer_norm/Add': 'FLOAT', 'encoder/layers.3/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.3/final_layer_norm/Div': 'FLOAT', 'encoder/layers.3/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.4/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.4/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.4/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.4/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.4/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.4/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.4/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.4/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.4/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.4/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.4/final_layer_norm/Add': 'FLOAT', 'encoder/layers.4/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.4/final_layer_norm/Div': 'FLOAT', 'encoder/layers.4/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.5/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.5/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.5/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.5/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.5/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.5/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.5/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.5/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.5/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.5/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.5/final_layer_norm/Add': 'FLOAT', 'encoder/layers.5/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.5/final_layer_norm/Div': 'FLOAT', 'encoder/layers.5/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.6/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.6/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.6/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.6/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.6/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.6/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.6/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.6/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.6/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.6/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.6/final_layer_norm/Add': 'FLOAT', 'encoder/layers.6/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.6/final_layer_norm/Div': 'FLOAT', 'encoder/layers.6/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.7/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.7/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.7/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.7/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.7/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.7/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.7/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.7/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.7/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.7/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.7/final_layer_norm/Add': 'FLOAT', 'encoder/layers.7/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.7/final_layer_norm/Div': 'FLOAT', 'encoder/layers.7/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.8/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.8/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.8/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.8/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.8/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.8/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.8/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.8/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.8/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.8/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.8/final_layer_norm/Add': 'FLOAT', 'encoder/layers.8/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.8/final_layer_norm/Div': 'FLOAT', 'encoder/layers.8/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.9/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.9/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.9/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.9/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.9/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.9/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.9/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.9/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.9/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.9/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.9/final_layer_norm/Add': 'FLOAT', 'encoder/layers.9/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.9/final_layer_norm/Div': 'FLOAT', 'encoder/layers.9/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.10/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.10/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.10/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.10/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.10/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.10/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.10/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.10/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.10/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.10/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.10/final_layer_norm/Add': 'FLOAT', 'encoder/layers.10/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.10/final_layer_norm/Div': 'FLOAT', 'encoder/layers.10/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.11/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.11/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.11/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.11/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.11/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.11/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.11/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.11/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.11/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.11/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.11/final_layer_norm/Add': 'FLOAT', 'encoder/layers.11/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.11/final_layer_norm/Div': 'FLOAT', 'encoder/layers.11/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.12/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.12/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.12/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.12/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.12/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.12/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.12/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.12/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.12/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.12/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.12/final_layer_norm/Add': 'FLOAT', 'encoder/layers.12/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.12/final_layer_norm/Div': 'FLOAT', 'encoder/layers.12/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.13/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.13/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.13/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.13/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.13/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.13/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.13/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.13/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.13/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.13/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.13/final_layer_norm/Add': 'FLOAT', 'encoder/layers.13/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.13/final_layer_norm/Div': 'FLOAT', 'encoder/layers.13/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.14/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.14/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.14/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.14/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.14/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.14/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.14/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.14/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.14/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.14/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.14/final_layer_norm/Add': 'FLOAT', 'encoder/layers.14/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.14/final_layer_norm/Div': 'FLOAT', 'encoder/layers.14/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.15/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.15/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.15/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.15/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.15/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.15/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.15/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.15/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.15/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.15/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.15/final_layer_norm/Add': 'FLOAT', 'encoder/layers.15/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.15/final_layer_norm/Div': 'FLOAT', 'encoder/layers.15/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.16/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.16/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.16/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.16/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.16/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.16/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.16/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.16/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.16/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.16/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.16/final_layer_norm/Add': 'FLOAT', 'encoder/layers.16/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.16/final_layer_norm/Div': 'FLOAT', 'encoder/layers.16/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.17/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.17/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.17/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.17/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.17/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.17/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.17/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.17/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.17/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.17/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.17/final_layer_norm/Add': 'FLOAT', 'encoder/layers.17/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.17/final_layer_norm/Div': 'FLOAT', 'encoder/layers.17/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.18/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.18/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.18/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.18/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.18/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.18/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.18/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.18/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.18/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.18/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.18/final_layer_norm/Add': 'FLOAT', 'encoder/layers.18/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.18/final_layer_norm/Div': 'FLOAT', 'encoder/layers.18/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.19/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.19/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.19/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.19/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.19/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.19/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.19/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.19/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.19/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.19/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.19/final_layer_norm/Add': 'FLOAT', 'encoder/layers.19/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.19/final_layer_norm/Div': 'FLOAT', 'encoder/layers.19/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.20/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.20/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.20/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.20/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.20/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.20/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.20/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.20/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.20/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.20/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.20/final_layer_norm/Add': 'FLOAT', 'encoder/layers.20/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.20/final_layer_norm/Div': 'FLOAT', 'encoder/layers.20/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.21/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.21/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.21/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.21/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.21/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.21/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.21/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.21/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.21/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.21/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.21/final_layer_norm/Add': 'FLOAT', 'encoder/layers.21/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.21/final_layer_norm/Div': 'FLOAT', 'encoder/layers.21/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.22/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.22/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.22/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.22/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.22/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.22/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.22/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.22/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.22/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.22/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.22/final_layer_norm/Add': 'FLOAT', 'encoder/layers.22/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.22/final_layer_norm/Div': 'FLOAT', 'encoder/layers.22/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.23/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.23/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.23/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.23/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.23/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.23/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.23/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.23/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.23/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.23/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.23/final_layer_norm/Add': 'FLOAT', 'encoder/layers.23/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.23/final_layer_norm/Div': 'FLOAT', 'encoder/layers.23/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.24/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.24/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.24/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.24/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.24/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.24/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.24/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.24/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.24/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.24/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.24/final_layer_norm/Add': 'FLOAT', 'encoder/layers.24/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.24/final_layer_norm/Div': 'FLOAT', 'encoder/layers.24/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.25/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.25/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.25/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.25/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.25/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.25/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.25/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.25/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.25/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.25/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.25/final_layer_norm/Add': 'FLOAT', 'encoder/layers.25/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.25/final_layer_norm/Div': 'FLOAT', 'encoder/layers.25/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.26/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.26/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.26/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.26/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.26/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.26/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.26/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.26/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.26/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.26/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.26/final_layer_norm/Add': 'FLOAT', 'encoder/layers.26/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.26/final_layer_norm/Div': 'FLOAT', 'encoder/layers.26/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.27/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.27/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.27/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.27/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.27/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.27/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.27/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.27/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.27/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.27/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.27/final_layer_norm/Add': 'FLOAT', 'encoder/layers.27/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.27/final_layer_norm/Div': 'FLOAT', 'encoder/layers.27/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.28/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.28/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.28/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.28/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.28/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.28/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.28/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.28/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.28/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.28/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.28/final_layer_norm/Add': 'FLOAT', 'encoder/layers.28/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.28/final_layer_norm/Div': 'FLOAT', 'encoder/layers.28/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.29/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.29/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.29/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.29/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.29/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.29/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.29/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.29/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.29/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.29/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.29/final_layer_norm/Add': 'FLOAT', 'encoder/layers.29/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.29/final_layer_norm/Div': 'FLOAT', 'encoder/layers.29/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.30/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.30/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.30/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.30/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.30/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.30/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.30/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.30/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.30/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.30/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.30/final_layer_norm/Add': 'FLOAT', 'encoder/layers.30/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.30/final_layer_norm/Div': 'FLOAT', 'encoder/layers.30/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.31/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.31/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.31/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.31/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.31/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.31/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.31/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.31/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.31/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.31/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.31/final_layer_norm/Add': 'FLOAT', 'encoder/layers.31/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.31/final_layer_norm/Div': 'FLOAT', 'encoder/layers.31/final_layer_norm/Mul': 'FLOAT', 'encoder/layer_norm/ReduceMean': 'FLOAT', 'encoder/layer_norm/Pow': 'FLOAT', 'encoder/layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layer_norm/Add': 'FLOAT', 'encoder/layer_norm/Sqrt': 'FLOAT', 'encoder/layer_norm/Div': 'FLOAT', 'encoder/layer_norm/Mul': 'FLOAT'}\u001b[0m\n",
      "\u001b[38;5;11m[W] onnx2trt_utils.cpp:400: One or more weights outside the range of INT32 was clamped\u001b[0m\n",
      "\u001b[38;5;11m[W] It looks like some layers in the network have compute precision set, but precision constraints were not enabled. \n",
      "    Precision constraints must be set to 'prefer' or 'obey' for layer compute precision to take effect. \n",
      "    Note: Layers and their requested precisions were: {'/decoder/layers.0/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.0/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.0/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.0/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.0/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.0/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.0/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.0/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.0/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.0/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.0/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.0/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.0/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.0/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.0/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.0/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.0/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.0/final_layer_norm/Add': 'FLOAT', '/decoder/layers.0/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.0/final_layer_norm/Div': 'FLOAT', '/decoder/layers.0/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.1/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.1/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.1/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.1/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.1/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.1/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.1/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.1/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.1/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.1/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.1/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.1/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.1/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.1/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.1/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.1/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.1/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.1/final_layer_norm/Add': 'FLOAT', '/decoder/layers.1/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.1/final_layer_norm/Div': 'FLOAT', '/decoder/layers.1/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.2/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.2/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.2/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.2/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.2/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.2/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.2/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.2/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.2/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.2/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.2/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.2/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.2/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.2/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.2/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.2/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.2/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.2/final_layer_norm/Add': 'FLOAT', '/decoder/layers.2/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.2/final_layer_norm/Div': 'FLOAT', '/decoder/layers.2/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.3/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.3/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.3/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.3/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.3/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.3/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.3/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.3/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.3/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.3/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.3/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.3/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.3/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.3/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.3/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.3/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.3/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.3/final_layer_norm/Add': 'FLOAT', '/decoder/layers.3/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.3/final_layer_norm/Div': 'FLOAT', '/decoder/layers.3/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.4/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.4/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.4/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.4/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.4/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.4/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.4/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.4/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.4/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.4/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.4/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.4/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.4/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.4/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.4/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.4/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.4/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.4/final_layer_norm/Add': 'FLOAT', '/decoder/layers.4/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.4/final_layer_norm/Div': 'FLOAT', '/decoder/layers.4/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.5/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.5/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.5/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.5/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.5/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.5/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.5/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.5/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.5/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.5/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.5/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.5/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.5/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.5/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.5/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.5/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.5/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.5/final_layer_norm/Add': 'FLOAT', '/decoder/layers.5/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.5/final_layer_norm/Div': 'FLOAT', '/decoder/layers.5/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.6/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.6/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.6/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.6/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.6/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.6/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.6/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.6/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.6/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.6/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.6/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.6/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.6/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.6/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.6/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.6/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.6/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.6/final_layer_norm/Add': 'FLOAT', '/decoder/layers.6/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.6/final_layer_norm/Div': 'FLOAT', '/decoder/layers.6/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.7/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.7/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.7/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.7/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.7/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.7/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.7/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.7/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.7/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.7/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.7/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.7/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.7/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.7/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.7/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.7/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.7/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.7/final_layer_norm/Add': 'FLOAT', '/decoder/layers.7/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.7/final_layer_norm/Div': 'FLOAT', '/decoder/layers.7/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.8/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.8/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.8/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.8/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.8/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.8/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.8/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.8/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.8/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.8/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.8/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.8/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.8/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.8/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.8/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.8/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.8/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.8/final_layer_norm/Add': 'FLOAT', '/decoder/layers.8/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.8/final_layer_norm/Div': 'FLOAT', '/decoder/layers.8/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.9/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.9/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.9/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.9/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.9/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.9/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.9/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.9/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.9/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.9/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.9/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.9/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.9/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.9/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.9/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.9/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.9/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.9/final_layer_norm/Add': 'FLOAT', '/decoder/layers.9/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.9/final_layer_norm/Div': 'FLOAT', '/decoder/layers.9/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.10/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.10/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.10/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.10/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.10/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.10/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.10/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.10/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.10/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.10/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.10/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.10/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.10/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.10/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.10/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.10/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.10/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.10/final_layer_norm/Add': 'FLOAT', '/decoder/layers.10/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.10/final_layer_norm/Div': 'FLOAT', '/decoder/layers.10/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.11/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.11/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.11/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.11/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.11/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.11/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.11/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.11/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.11/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.11/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.11/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.11/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.11/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.11/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.11/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.11/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.11/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.11/final_layer_norm/Add': 'FLOAT', '/decoder/layers.11/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.11/final_layer_norm/Div': 'FLOAT', '/decoder/layers.11/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.12/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.12/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.12/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.12/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.12/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.12/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.12/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.12/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.12/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.12/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.12/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.12/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.12/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.12/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.12/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.12/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.12/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.12/final_layer_norm/Add': 'FLOAT', '/decoder/layers.12/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.12/final_layer_norm/Div': 'FLOAT', '/decoder/layers.12/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.13/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.13/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.13/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.13/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.13/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.13/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.13/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.13/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.13/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.13/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.13/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.13/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.13/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.13/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.13/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.13/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.13/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.13/final_layer_norm/Add': 'FLOAT', '/decoder/layers.13/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.13/final_layer_norm/Div': 'FLOAT', '/decoder/layers.13/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.14/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.14/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.14/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.14/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.14/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.14/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.14/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.14/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.14/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.14/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.14/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.14/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.14/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.14/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.14/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.14/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.14/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.14/final_layer_norm/Add': 'FLOAT', '/decoder/layers.14/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.14/final_layer_norm/Div': 'FLOAT', '/decoder/layers.14/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.15/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.15/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.15/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.15/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.15/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.15/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.15/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.15/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.15/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.15/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.15/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.15/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.15/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.15/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.15/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.15/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.15/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.15/final_layer_norm/Add': 'FLOAT', '/decoder/layers.15/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.15/final_layer_norm/Div': 'FLOAT', '/decoder/layers.15/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.16/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.16/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.16/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.16/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.16/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.16/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.16/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.16/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.16/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.16/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.16/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.16/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.16/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.16/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.16/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.16/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.16/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.16/final_layer_norm/Add': 'FLOAT', '/decoder/layers.16/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.16/final_layer_norm/Div': 'FLOAT', '/decoder/layers.16/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.17/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.17/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.17/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.17/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.17/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.17/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.17/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.17/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.17/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.17/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.17/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.17/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.17/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.17/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.17/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.17/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.17/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.17/final_layer_norm/Add': 'FLOAT', '/decoder/layers.17/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.17/final_layer_norm/Div': 'FLOAT', '/decoder/layers.17/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.18/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.18/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.18/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.18/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.18/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.18/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.18/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.18/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.18/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.18/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.18/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.18/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.18/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.18/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.18/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.18/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.18/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.18/final_layer_norm/Add': 'FLOAT', '/decoder/layers.18/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.18/final_layer_norm/Div': 'FLOAT', '/decoder/layers.18/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.19/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.19/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.19/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.19/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.19/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.19/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.19/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.19/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.19/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.19/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.19/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.19/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.19/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.19/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.19/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.19/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.19/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.19/final_layer_norm/Add': 'FLOAT', '/decoder/layers.19/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.19/final_layer_norm/Div': 'FLOAT', '/decoder/layers.19/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.20/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.20/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.20/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.20/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.20/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.20/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.20/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.20/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.20/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.20/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.20/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.20/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.20/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.20/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.20/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.20/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.20/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.20/final_layer_norm/Add': 'FLOAT', '/decoder/layers.20/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.20/final_layer_norm/Div': 'FLOAT', '/decoder/layers.20/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.21/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.21/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.21/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.21/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.21/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.21/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.21/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.21/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.21/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.21/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.21/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.21/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.21/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.21/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.21/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.21/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.21/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.21/final_layer_norm/Add': 'FLOAT', '/decoder/layers.21/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.21/final_layer_norm/Div': 'FLOAT', '/decoder/layers.21/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.22/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.22/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.22/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.22/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.22/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.22/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.22/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.22/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.22/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.22/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.22/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.22/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.22/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.22/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.22/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.22/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.22/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.22/final_layer_norm/Add': 'FLOAT', '/decoder/layers.22/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.22/final_layer_norm/Div': 'FLOAT', '/decoder/layers.22/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.23/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.23/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.23/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.23/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.23/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.23/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.23/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.23/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.23/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.23/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.23/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.23/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.23/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.23/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.23/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.23/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.23/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.23/final_layer_norm/Add': 'FLOAT', '/decoder/layers.23/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.23/final_layer_norm/Div': 'FLOAT', '/decoder/layers.23/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.24/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.24/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.24/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.24/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.24/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.24/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.24/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.24/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.24/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.24/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.24/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.24/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.24/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.24/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.24/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.24/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.24/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.24/final_layer_norm/Add': 'FLOAT', '/decoder/layers.24/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.24/final_layer_norm/Div': 'FLOAT', '/decoder/layers.24/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.25/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.25/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.25/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.25/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.25/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.25/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.25/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.25/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.25/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.25/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.25/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.25/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.25/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.25/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.25/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.25/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.25/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.25/final_layer_norm/Add': 'FLOAT', '/decoder/layers.25/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.25/final_layer_norm/Div': 'FLOAT', '/decoder/layers.25/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.26/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.26/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.26/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.26/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.26/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.26/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.26/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.26/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.26/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.26/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.26/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.26/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.26/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.26/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.26/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.26/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.26/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.26/final_layer_norm/Add': 'FLOAT', '/decoder/layers.26/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.26/final_layer_norm/Div': 'FLOAT', '/decoder/layers.26/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.27/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.27/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.27/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.27/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.27/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.27/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.27/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.27/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.27/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.27/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.27/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.27/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.27/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.27/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.27/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.27/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.27/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.27/final_layer_norm/Add': 'FLOAT', '/decoder/layers.27/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.27/final_layer_norm/Div': 'FLOAT', '/decoder/layers.27/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.28/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.28/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.28/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.28/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.28/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.28/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.28/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.28/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.28/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.28/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.28/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.28/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.28/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.28/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.28/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.28/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.28/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.28/final_layer_norm/Add': 'FLOAT', '/decoder/layers.28/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.28/final_layer_norm/Div': 'FLOAT', '/decoder/layers.28/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.29/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.29/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.29/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.29/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.29/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.29/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.29/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.29/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.29/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.29/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.29/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.29/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.29/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.29/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.29/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.29/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.29/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.29/final_layer_norm/Add': 'FLOAT', '/decoder/layers.29/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.29/final_layer_norm/Div': 'FLOAT', '/decoder/layers.29/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.30/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.30/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.30/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.30/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.30/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.30/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.30/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.30/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.30/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.30/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.30/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.30/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.30/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.30/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.30/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.30/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.30/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.30/final_layer_norm/Add': 'FLOAT', '/decoder/layers.30/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.30/final_layer_norm/Div': 'FLOAT', '/decoder/layers.30/final_layer_norm/Mul': 'FLOAT', '/decoder/layers.31/self_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.31/self_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.31/self_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.31/self_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.31/self_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.31/self_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.31/self_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.31/encoder_attn_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.31/encoder_attn_layer_norm/Pow': 'FLOAT', '/decoder/layers.31/encoder_attn_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.31/encoder_attn_layer_norm/Add': 'FLOAT', '/decoder/layers.31/encoder_attn_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.31/encoder_attn_layer_norm/Div': 'FLOAT', '/decoder/layers.31/encoder_attn_layer_norm/Mul': 'FLOAT', '/decoder/layers.31/final_layer_norm/ReduceMean': 'FLOAT', '/decoder/layers.31/final_layer_norm/Pow': 'FLOAT', '/decoder/layers.31/final_layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layers.31/final_layer_norm/Add': 'FLOAT', '/decoder/layers.31/final_layer_norm/Sqrt': 'FLOAT', '/decoder/layers.31/final_layer_norm/Div': 'FLOAT', '/decoder/layers.31/final_layer_norm/Mul': 'FLOAT', '/decoder/layer_norm/ReduceMean': 'FLOAT', '/decoder/layer_norm/Pow': 'FLOAT', '/decoder/layer_norm/ReduceMean_1': 'FLOAT', '/decoder/layer_norm/Add': 'FLOAT', '/decoder/layer_norm/Sqrt': 'FLOAT', '/decoder/layer_norm/Div': 'FLOAT', '/decoder/layer_norm/Mul': 'FLOAT'}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "force_write=True\n",
    "engine_tag = f\"bs{batch_size}\"\n",
    "\n",
    "if num_beams > 1:\n",
    "    engine_tag += \"-beam{}\".format(num_beams)\n",
    "\n",
    "preview_features = [PreviewFeature.DISABLE_EXTERNAL_TACTIC_SOURCES_FOR_CORE_0805]\n",
    "if disable_preview_dynamic_shapes:\n",
    "    engine_tag += \"-noPreviewFasterDynamicShapes\"\n",
    "else:\n",
    "    preview_features.append(PreviewFeature.FASTER_DYNAMIC_SHAPES_0805)\n",
    "\n",
    "# FP32\n",
    "wh_encoder_engine_name = os.path.join(wh_tensorrt_model_path, wh_encoder_onnx_model_fpath) + f\"-{engine_tag}.engine\".replace(f\"-beam{num_beams}\", \"\") # encoder engine not affected by beam search\n",
    "wh_decoder_engine_name = os.path.join(wh_tensorrt_model_path, wh_decoder_onnx_model_fpath) + f\"-{engine_tag}.engine\"\n",
    "\n",
    "if not os.path.exists(wh_encoder_engine_name) or force_write:\n",
    "    whisper_trt_encoder_engine = WhisperEncoderONNXFile(os.path.join(wh_onnx_model_path, wh_encoder_onnx_model_fpath), metadata).as_trt_engine(\n",
    "        wh_encoder_engine_name, \n",
    "        force_overwrite=force_write,\n",
    "        profiles=[encoder_profile], \n",
    "        preview_features=preview_features\n",
    "    )\n",
    "else:\n",
    "    whisper_trt_encoder_engine = WhisperEncoderTRTEngine(wh_encoder_engine_name, metadata)\n",
    "    \n",
    "if not os.path.exists(wh_decoder_engine_name) or force_write:\n",
    "    whisper_trt_decoder_engine = WhisperDecoderONNXFile(os.path.join(wh_onnx_model_path, wh_decoder_onnx_model_fpath), metadata).as_trt_engine(\n",
    "        wh_decoder_engine_name, \n",
    "        force_overwrite=force_write,\n",
    "        profiles=[decoder_profile], \n",
    "        preview_features=preview_features\n",
    "    )\n",
    "else:\n",
    "    whisper_trt_decoder_engine = WhisperDecoderTRTEngine(wh_decoder_engine_name, metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "efba83df-ffd5-4ea5-b74d-070d045d83ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;11m[W] It looks like some layers in the network have compute precision set, but precision constraints were not enabled. \n",
      "    Precision constraints must be set to 'prefer' or 'obey' for layer compute precision to take effect. \n",
      "    Note: Layers and their requested precisions were: {'encoder/layers.0/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.0/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.0/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.0/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.0/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.0/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.0/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.0/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.0/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.0/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.0/final_layer_norm/Add': 'FLOAT', 'encoder/layers.0/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.0/final_layer_norm/Div': 'FLOAT', 'encoder/layers.0/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.1/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.1/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.1/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.1/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.1/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.1/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.1/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.1/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.1/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.1/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.1/final_layer_norm/Add': 'FLOAT', 'encoder/layers.1/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.1/final_layer_norm/Div': 'FLOAT', 'encoder/layers.1/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.2/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.2/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.2/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.2/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.2/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.2/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.2/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.2/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.2/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.2/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.2/final_layer_norm/Add': 'FLOAT', 'encoder/layers.2/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.2/final_layer_norm/Div': 'FLOAT', 'encoder/layers.2/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.3/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.3/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.3/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.3/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.3/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.3/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.3/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.3/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.3/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.3/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.3/final_layer_norm/Add': 'FLOAT', 'encoder/layers.3/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.3/final_layer_norm/Div': 'FLOAT', 'encoder/layers.3/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.4/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.4/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.4/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.4/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.4/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.4/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.4/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.4/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.4/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.4/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.4/final_layer_norm/Add': 'FLOAT', 'encoder/layers.4/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.4/final_layer_norm/Div': 'FLOAT', 'encoder/layers.4/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.5/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.5/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.5/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.5/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.5/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.5/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.5/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.5/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.5/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.5/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.5/final_layer_norm/Add': 'FLOAT', 'encoder/layers.5/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.5/final_layer_norm/Div': 'FLOAT', 'encoder/layers.5/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.6/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.6/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.6/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.6/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.6/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.6/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.6/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.6/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.6/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.6/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.6/final_layer_norm/Add': 'FLOAT', 'encoder/layers.6/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.6/final_layer_norm/Div': 'FLOAT', 'encoder/layers.6/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.7/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.7/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.7/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.7/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.7/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.7/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.7/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.7/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.7/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.7/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.7/final_layer_norm/Add': 'FLOAT', 'encoder/layers.7/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.7/final_layer_norm/Div': 'FLOAT', 'encoder/layers.7/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.8/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.8/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.8/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.8/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.8/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.8/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.8/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.8/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.8/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.8/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.8/final_layer_norm/Add': 'FLOAT', 'encoder/layers.8/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.8/final_layer_norm/Div': 'FLOAT', 'encoder/layers.8/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.9/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.9/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.9/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.9/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.9/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.9/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.9/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.9/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.9/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.9/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.9/final_layer_norm/Add': 'FLOAT', 'encoder/layers.9/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.9/final_layer_norm/Div': 'FLOAT', 'encoder/layers.9/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.10/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.10/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.10/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.10/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.10/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.10/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.10/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.10/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.10/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.10/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.10/final_layer_norm/Add': 'FLOAT', 'encoder/layers.10/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.10/final_layer_norm/Div': 'FLOAT', 'encoder/layers.10/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.11/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.11/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.11/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.11/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.11/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.11/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.11/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.11/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.11/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.11/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.11/final_layer_norm/Add': 'FLOAT', 'encoder/layers.11/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.11/final_layer_norm/Div': 'FLOAT', 'encoder/layers.11/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.12/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.12/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.12/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.12/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.12/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.12/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.12/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.12/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.12/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.12/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.12/final_layer_norm/Add': 'FLOAT', 'encoder/layers.12/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.12/final_layer_norm/Div': 'FLOAT', 'encoder/layers.12/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.13/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.13/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.13/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.13/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.13/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.13/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.13/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.13/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.13/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.13/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.13/final_layer_norm/Add': 'FLOAT', 'encoder/layers.13/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.13/final_layer_norm/Div': 'FLOAT', 'encoder/layers.13/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.14/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.14/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.14/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.14/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.14/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.14/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.14/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.14/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.14/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.14/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.14/final_layer_norm/Add': 'FLOAT', 'encoder/layers.14/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.14/final_layer_norm/Div': 'FLOAT', 'encoder/layers.14/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.15/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.15/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.15/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.15/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.15/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.15/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.15/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.15/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.15/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.15/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.15/final_layer_norm/Add': 'FLOAT', 'encoder/layers.15/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.15/final_layer_norm/Div': 'FLOAT', 'encoder/layers.15/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.16/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.16/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.16/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.16/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.16/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.16/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.16/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.16/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.16/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.16/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.16/final_layer_norm/Add': 'FLOAT', 'encoder/layers.16/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.16/final_layer_norm/Div': 'FLOAT', 'encoder/layers.16/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.17/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.17/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.17/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.17/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.17/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.17/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.17/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.17/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.17/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.17/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.17/final_layer_norm/Add': 'FLOAT', 'encoder/layers.17/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.17/final_layer_norm/Div': 'FLOAT', 'encoder/layers.17/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.18/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.18/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.18/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.18/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.18/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.18/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.18/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.18/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.18/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.18/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.18/final_layer_norm/Add': 'FLOAT', 'encoder/layers.18/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.18/final_layer_norm/Div': 'FLOAT', 'encoder/layers.18/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.19/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.19/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.19/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.19/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.19/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.19/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.19/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.19/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.19/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.19/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.19/final_layer_norm/Add': 'FLOAT', 'encoder/layers.19/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.19/final_layer_norm/Div': 'FLOAT', 'encoder/layers.19/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.20/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.20/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.20/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.20/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.20/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.20/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.20/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.20/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.20/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.20/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.20/final_layer_norm/Add': 'FLOAT', 'encoder/layers.20/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.20/final_layer_norm/Div': 'FLOAT', 'encoder/layers.20/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.21/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.21/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.21/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.21/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.21/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.21/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.21/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.21/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.21/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.21/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.21/final_layer_norm/Add': 'FLOAT', 'encoder/layers.21/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.21/final_layer_norm/Div': 'FLOAT', 'encoder/layers.21/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.22/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.22/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.22/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.22/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.22/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.22/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.22/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.22/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.22/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.22/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.22/final_layer_norm/Add': 'FLOAT', 'encoder/layers.22/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.22/final_layer_norm/Div': 'FLOAT', 'encoder/layers.22/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.23/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.23/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.23/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.23/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.23/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.23/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.23/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.23/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.23/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.23/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.23/final_layer_norm/Add': 'FLOAT', 'encoder/layers.23/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.23/final_layer_norm/Div': 'FLOAT', 'encoder/layers.23/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.24/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.24/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.24/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.24/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.24/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.24/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.24/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.24/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.24/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.24/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.24/final_layer_norm/Add': 'FLOAT', 'encoder/layers.24/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.24/final_layer_norm/Div': 'FLOAT', 'encoder/layers.24/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.25/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.25/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.25/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.25/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.25/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.25/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.25/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.25/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.25/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.25/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.25/final_layer_norm/Add': 'FLOAT', 'encoder/layers.25/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.25/final_layer_norm/Div': 'FLOAT', 'encoder/layers.25/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.26/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.26/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.26/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.26/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.26/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.26/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.26/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.26/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.26/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.26/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.26/final_layer_norm/Add': 'FLOAT', 'encoder/layers.26/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.26/final_layer_norm/Div': 'FLOAT', 'encoder/layers.26/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.27/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.27/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.27/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.27/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.27/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.27/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.27/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.27/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.27/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.27/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.27/final_layer_norm/Add': 'FLOAT', 'encoder/layers.27/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.27/final_layer_norm/Div': 'FLOAT', 'encoder/layers.27/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.28/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.28/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.28/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.28/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.28/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.28/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.28/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.28/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.28/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.28/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.28/final_layer_norm/Add': 'FLOAT', 'encoder/layers.28/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.28/final_layer_norm/Div': 'FLOAT', 'encoder/layers.28/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.29/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.29/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.29/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.29/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.29/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.29/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.29/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.29/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.29/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.29/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.29/final_layer_norm/Add': 'FLOAT', 'encoder/layers.29/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.29/final_layer_norm/Div': 'FLOAT', 'encoder/layers.29/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.30/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.30/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.30/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.30/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.30/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.30/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.30/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.30/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.30/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.30/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.30/final_layer_norm/Add': 'FLOAT', 'encoder/layers.30/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.30/final_layer_norm/Div': 'FLOAT', 'encoder/layers.30/final_layer_norm/Mul': 'FLOAT', 'encoder/layers.31/self_attn_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.31/self_attn_layer_norm/Pow': 'FLOAT', 'encoder/layers.31/self_attn_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.31/self_attn_layer_norm/Add': 'FLOAT', 'encoder/layers.31/self_attn_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.31/self_attn_layer_norm/Div': 'FLOAT', 'encoder/layers.31/self_attn_layer_norm/Mul': 'FLOAT', 'encoder/layers.31/final_layer_norm/ReduceMean': 'FLOAT', 'encoder/layers.31/final_layer_norm/Pow': 'FLOAT', 'encoder/layers.31/final_layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layers.31/final_layer_norm/Add': 'FLOAT', 'encoder/layers.31/final_layer_norm/Sqrt': 'FLOAT', 'encoder/layers.31/final_layer_norm/Div': 'FLOAT', 'encoder/layers.31/final_layer_norm/Mul': 'FLOAT', 'encoder/layer_norm/ReduceMean': 'FLOAT', 'encoder/layer_norm/Pow': 'FLOAT', 'encoder/layer_norm/ReduceMean_1': 'FLOAT', 'encoder/layer_norm/Add': 'FLOAT', 'encoder/layer_norm/Sqrt': 'FLOAT', 'encoder/layer_norm/Div': 'FLOAT', 'encoder/layer_norm/Mul': 'FLOAT'}\u001b[0m\n",
      "\u001b[38;5;11m[W] Detected layernorm nodes in FP16: /decoder/layers.0/self_attn_layer_norm/Sub, , , , , , /decoder/layers.0/self_attn_layer_norm/Add_1, /decoder/layers.0/encoder_attn_layer_norm/Sub, , , , , , /decoder/layers.0/encoder_attn_layer_norm/Add_1, /decoder/layers.0/final_layer_norm/Sub, , , , , , /decoder/layers.0/final_layer_norm/Add_1, /decoder/layers.1/self_attn_layer_norm/Sub, , , , , , /decoder/layers.1/self_attn_layer_norm/Add_1, /decoder/layers.1/encoder_attn_layer_norm/Sub, , , , , , /decoder/layers.1/encoder_attn_layer_norm/Add_1, /decoder/layers.1/final_layer_norm/Sub, , , , , , /decoder/layers.1/final_layer_norm/Add_1, /decoder/layers.2/self_attn_layer_norm/Sub, , , , , , /decoder/layers.2/self_attn_layer_norm/Add_1, /decoder/layers.2/encoder_attn_layer_norm/Sub, , , , , , /decoder/layers.2/encoder_attn_layer_norm/Add_1, /decoder/layers.2/final_layer_norm/Sub, , , , , , /decoder/layers.2/final_layer_norm/Add_1, /decoder/layers.3/self_attn_layer_norm/Sub, , , , , , /decoder/layers.3/self_attn_layer_norm/Add_1, /decoder/layers.3/encoder_attn_layer_norm/Sub, , , , , , /decoder/layers.3/encoder_attn_layer_norm/Add_1, /decoder/layers.3/final_layer_norm/Sub, , , , , , /decoder/layers.3/final_layer_norm/Add_1, /decoder/layers.4/self_attn_layer_norm/Sub, , , , , , /decoder/layers.4/self_attn_layer_norm/Add_1, /decoder/layers.4/encoder_attn_layer_norm/Sub, , , , , , /decoder/layers.4/encoder_attn_layer_norm/Add_1, /decoder/layers.4/final_layer_norm/Sub, , , , , , , /decoder/layers.4/final_layer_norm/Add_1, /decoder/layers.5/self_attn_layer_norm/Sub, , , , , , , /decoder/layers.5/self_attn_layer_norm/Add_1, /decoder/layers.5/encoder_attn_layer_norm/Sub, , , , , , , /decoder/layers.5/encoder_attn_layer_norm/Add_1, /decoder/layers.5/final_layer_norm/Sub, , , , , , , /decoder/layers.5/final_layer_norm/Add_1, /decoder/layers.6/self_attn_layer_norm/Sub, , , , , , , /decoder/layers.6/self_attn_layer_norm/Add_1, /decoder/layers.6/encoder_attn_layer_norm/Sub, , , , , , , /decoder/layers.6/encoder_attn_layer_norm/Add_1, /decoder/layers.6/final_layer_norm/Sub, , , , , , , /decoder/layers.6/final_layer_norm/Add_1, /decoder/layers.7/self_attn_layer_norm/Sub, , , , , , , /decoder/layers.7/self_attn_layer_norm/Add_1, /decoder/layers.7/encoder_attn_layer_norm/Sub, , , , , , , /decoder/layers.7/encoder_attn_layer_norm/Add_1, /decoder/layers.7/final_layer_norm/Sub, , , , , , , /decoder/layers.7/final_layer_norm/Add_1, /decoder/layers.8/self_attn_layer_norm/Sub, , , , , , , /decoder/layers.8/self_attn_layer_norm/Add_1, /decoder/layers.8/encoder_attn_layer_norm/Sub, , , , , , , /decoder/layers.8/encoder_attn_layer_norm/Add_1, /decoder/layers.27/final_layer_norm/Sub, , , , , , , /decoder/layers.27/final_layer_norm/Add_1, /decoder/layers.28/self_attn_layer_norm/Sub, , , , , , , /decoder/layers.28/self_attn_layer_norm/Add_1, /decoder/layers.28/encoder_attn_layer_norm/Sub, , , , , , , /decoder/layers.28/encoder_attn_layer_norm/Add_1, /decoder/layers.28/final_layer_norm/Sub, , , , , , , /decoder/layers.28/final_layer_norm/Add_1, /decoder/layers.29/self_attn_layer_norm/Sub, , , , , , , /decoder/layers.29/self_attn_layer_norm/Add_1, /decoder/layers.29/encoder_attn_layer_norm/Sub, , , , , , , /decoder/layers.29/encoder_attn_layer_norm/Add_1, /decoder/layers.29/final_layer_norm/Sub, , , , , , , /decoder/layers.29/final_layer_norm/Add_1, /decoder/layers.30/self_attn_layer_norm/Sub, , , , , , , /decoder/layers.30/self_attn_layer_norm/Add_1, /decoder/layers.30/encoder_attn_layer_norm/Sub, , , , , , , /decoder/layers.30/encoder_attn_layer_norm/Add_1, /decoder/layers.30/final_layer_norm/Sub, , , , , , , /decoder/layers.30/final_layer_norm/Add_1, /decoder/layers.31/self_attn_layer_norm/Sub, , , , , , , /decoder/layers.31/self_attn_layer_norm/Add_1, /decoder/layers.31/encoder_attn_layer_norm/Sub, , , , , , , /decoder/layers.31/encoder_attn_layer_norm/Add_1, /decoder/layers.31/final_layer_norm/Sub, , , , , , , /decoder/layers.31/final_layer_norm/Add_1, /decoder/layer_norm/Sub, , , , , , , /decoder/layer_norm/Add_1, , , , /decoder/layers.18/encoder_attn_layer_norm/Sub, , , , , , , /decoder/layers.18/encoder_attn_layer_norm/Add_1, /decoder/layers.18/final_layer_norm/Sub, , , , , , , /decoder/layers.18/final_layer_norm/Add_1, /decoder/layers.19/self_attn_layer_norm/Sub, , , , , , , /decoder/layers.19/self_attn_layer_norm/Add_1, /decoder/layers.19/encoder_attn_layer_norm/Sub, , , , , , , /decoder/layers.19/encoder_attn_layer_norm/Add_1, /decoder/layers.19/final_layer_norm/Sub, , , , , , , /decoder/layers.19/final_layer_norm/Add_1, /decoder/layers.20/self_attn_layer_norm/Sub, , , , , , , /decoder/layers.20/self_attn_layer_norm/Add_1, /decoder/layers.20/encoder_attn_layer_norm/Sub, , , , , , , /decoder/layers.20/encoder_attn_layer_norm/Add_1, /decoder/layers.20/final_layer_norm/Sub, , , , , , , /decoder/layers.20/final_layer_norm/Add_1, /decoder/layers.21/self_attn_layer_norm/Sub, , , , , , , /decoder/layers.21/self_attn_layer_norm/Add_1, /decoder/layers.21/encoder_attn_layer_norm/Sub, , , , , , , /decoder/layers.21/encoder_attn_layer_norm/Add_1, /decoder/layers.21/final_layer_norm/Sub, , , , , , , /decoder/layers.21/final_layer_norm/Add_1, /decoder/layers.22/self_attn_layer_norm/Sub, , , , , , , /decoder/layers.22/self_attn_layer_norm/Add_1, /decoder/layers.22/encoder_attn_layer_norm/Sub, , , , , , , /decoder/layers.22/encoder_attn_layer_norm/Add_1, /decoder/layers.22/final_layer_norm/Sub, , , , , , , /decoder/layers.22/final_layer_norm/Add_1, /decoder/layers.23/self_attn_layer_norm/Sub, , , , , , , /decoder/layers.23/self_attn_layer_norm/Add_1, /decoder/layers.23/encoder_attn_layer_norm/Sub, , , , , , , /decoder/layers.23/encoder_attn_layer_norm/Add_1, /decoder/layers.23/final_layer_norm/Sub, , , , , , , /decoder/layers.23/final_layer_norm/Add_1, /decoder/layers.24/self_attn_layer_norm/Sub, , , , , , , /decoder/layers.24/self_attn_layer_norm/Add_1, /decoder/layers.24/encoder_attn_layer_norm/Sub, , , , , , , /decoder/layers.24/encoder_attn_layer_norm/Add_1, /decoder/layers.24/final_layer_norm/Sub, , , , , , , /decoder/layers.24/final_layer_norm/Add_1, /decoder/layers.25/self_attn_layer_norm/Sub, , , , , , , /decoder/layers.25/self_attn_layer_norm/Add_1, /decoder/layers.25/encoder_attn_layer_norm/Sub, , , , , , , /decoder/layers.25/encoder_attn_layer_norm/Add_1, /decoder/layers.25/final_layer_norm/Sub, , , , , , , /decoder/layers.25/final_layer_norm/Add_1, /decoder/layers.26/self_attn_layer_norm/Sub, , , , , , , /decoder/layers.26/self_attn_layer_norm/Add_1, /decoder/layers.26/encoder_attn_layer_norm/Sub, , , , , , , /decoder/layers.26/encoder_attn_layer_norm/Add_1, /decoder/layers.26/final_layer_norm/Sub, , , , , , , /decoder/layers.26/final_layer_norm/Add_1, /decoder/layers.27/self_attn_layer_norm/Sub, , , , , , , /decoder/layers.27/self_attn_layer_norm/Add_1, /decoder/layers.27/encoder_attn_layer_norm/Sub, , , , , , , /decoder/layers.27/encoder_attn_layer_norm/Add_1, , , , , , , , , , , , /decoder/layers.8/final_layer_norm/Sub, , , , , , , /decoder/layers.8/final_layer_norm/Add_1, /decoder/layers.9/self_attn_layer_norm/Sub, , , , , , , /decoder/layers.9/self_attn_layer_norm/Add_1, /decoder/layers.9/encoder_attn_layer_norm/Sub, , , , , , , /decoder/layers.9/encoder_attn_layer_norm/Add_1, /decoder/layers.9/final_layer_norm/Sub, , , , , , , /decoder/layers.9/final_layer_norm/Add_1, /decoder/layers.10/self_attn_layer_norm/Sub, , , , , , , /decoder/layers.10/self_attn_layer_norm/Add_1, /decoder/layers.10/encoder_attn_layer_norm/Sub, , , , , , , /decoder/layers.10/encoder_attn_layer_norm/Add_1, /decoder/layers.10/final_layer_norm/Sub, , , , , , , /decoder/layers.10/final_layer_norm/Add_1, /decoder/layers.11/self_attn_layer_norm/Sub, , , , , , , /decoder/layers.11/self_attn_layer_norm/Add_1, /decoder/layers.11/encoder_attn_layer_norm/Sub, , , , , , , /decoder/layers.11/encoder_attn_layer_norm/Add_1, /decoder/layers.11/final_layer_norm/Sub, , , , , , , /decoder/layers.11/final_layer_norm/Add_1, /decoder/layers.12/self_attn_layer_norm/Sub, , , , , , , /decoder/layers.12/self_attn_layer_norm/Add_1, /decoder/layers.12/encoder_attn_layer_norm/Sub, , , , , , , /decoder/layers.12/encoder_attn_layer_norm/Add_1, /decoder/layers.12/final_layer_norm/Sub, , , , , , , /decoder/layers.12/final_layer_norm/Add_1, /decoder/layers.13/self_attn_layer_norm/Sub, , , , , , , /decoder/layers.13/self_attn_layer_norm/Add_1, /decoder/layers.13/encoder_attn_layer_norm/Sub, , , , , , , /decoder/layers.13/encoder_attn_layer_norm/Add_1, /decoder/layers.13/final_layer_norm/Sub, , , , , , , /decoder/layers.13/final_layer_norm/Add_1, /decoder/layers.14/self_attn_layer_norm/Sub, , , , , , , /decoder/layers.14/self_attn_layer_norm/Add_1, /decoder/layers.14/encoder_attn_layer_norm/Sub, , , , , , , /decoder/layers.14/encoder_attn_layer_norm/Add_1, /decoder/layers.14/final_layer_norm/Sub, , , , , , , /decoder/layers.14/final_layer_norm/Add_1, /decoder/layers.15/self_attn_layer_norm/Sub, , , , , , , /decoder/layers.15/self_attn_layer_norm/Add_1, /decoder/layers.15/encoder_attn_layer_norm/Sub, , , , , , , /decoder/layers.15/encoder_attn_layer_norm/Add_1, /decoder/layers.15/final_layer_norm/Sub, , , , , , , /decoder/layers.15/final_layer_norm/Add_1, /decoder/layers.16/self_attn_layer_norm/Sub, , , , , , , /decoder/layers.16/self_attn_layer_norm/Add_1, /decoder/layers.16/encoder_attn_layer_norm/Sub, , , , , , , /decoder/layers.16/encoder_attn_layer_norm/Add_1, /decoder/layers.16/final_layer_norm/Sub, , , , , , , /decoder/layers.16/final_layer_norm/Add_1, /decoder/layers.17/self_attn_layer_norm/Sub, , , , , , , /decoder/layers.17/self_attn_layer_norm/Add_1, /decoder/layers.17/encoder_attn_layer_norm/Sub, , , , , , , /decoder/layers.17/encoder_attn_layer_norm/Add_1, /decoder/layers.17/final_layer_norm/Sub, , , , , , , /decoder/layers.17/final_layer_norm/Add_1, /decoder/layers.18/self_attn_layer_norm/Sub, , , , , , , /decoder/layers.18/self_attn_layer_norm/Add_1\u001b[0m\n",
      "\u001b[38;5;11m[W] Running layernorm after self-attention in FP16 may cause overflow. Exporting the model to the latest available ONNX opset (later than opset 17) to use the INormalizationLayer, or forcing layernorm layers to run in FP32 precision can help with preserving accuracy.\u001b[0m\n",
      "\u001b[38;5;11m[W] TensorRT encountered issues when converting weights between types and that could affect accuracy.\u001b[0m\n",
      "\u001b[38;5;11m[W] If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.\u001b[0m\n",
      "\u001b[38;5;11m[W] Check verbose logs for the list of affected weights.\u001b[0m\n",
      "\u001b[38;5;11m[W] - 727 weights are affected by this issue: Detected subnormal FP16 values.\u001b[0m\n",
      "\u001b[38;5;11m[W] - 1 weights are affected by this issue: Detected finite FP32 values which would overflow in FP16 and converted them to the closest finite FP16 value.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# FP16\n",
    "wh_encoder_engine_name_fp16 = os.path.join(wh_tensorrt_model_path, wh_encoder_onnx_model_fpath_fp16) + f\"-{engine_tag}.engine\".replace(f\"-beam{num_beams}\", \"\") # encoder engine not affected by beam search\n",
    "wh_decoder_engine_name_fp16 = os.path.join(wh_tensorrt_model_path, wh_decoder_onnx_model_fpath_fp16) + f\"-{engine_tag}.engine\"\n",
    "\n",
    "if not os.path.exists(wh_encoder_engine_name_fp16) or force_write:\n",
    "    whisper_trt_encoder_engine_fp16 = WhisperEncoderONNXFile(os.path.join(wh_onnx_model_path, wh_encoder_onnx_model_fpath_fp16), metadata_fp16).as_trt_engine(\n",
    "        wh_encoder_engine_name_fp16, \n",
    "        force_overwrite=force_write,\n",
    "        profiles=[encoder_profile],\n",
    "        preview_features=preview_features\n",
    "    )\n",
    "else:\n",
    "    whisper_trt_encoder_engine_fp16 = WhisperEncoderTRTEngine(wh_encoder_engine_name_fp16, metadata_fp16)\n",
    "    \n",
    "if not os.path.exists(wh_decoder_engine_name_fp16) or force_write:\n",
    "    whisper_trt_decoder_engine_fp16 = WhisperDecoderONNXFile(os.path.join(wh_onnx_model_path, wh_decoder_onnx_model_fpath_fp16), metadata_fp16).as_trt_engine(\n",
    "        wh_decoder_engine_name_fp16, \n",
    "        force_overwrite=force_write,\n",
    "        profiles=[decoder_profile], \n",
    "        preview_features=preview_features\n",
    "    )\n",
    "else:\n",
    "    whisper_trt_decoder_engine_fp16 = WhisperDecoderTRTEngine(wh_decoder_engine_name_fp16, metadata_fp16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d3159336-afc4-4446-8652-f6db14ca3819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./models/openai/whisper-large-v2/tensorrt/Whisper-large-v2-fp16-encoder.onnx-bs1.engine'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wh_encoder_engine_name_fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "033c3627-d054-4bec-8e09-a6daf145021b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whisper-large-v2-encoder.onnx\n",
      "Whisper-large-v2-decoder-with-lm-head.onnx\n",
      "<Whisper.export.WhisperEncoderONNXFile object at 0x7f00ec4cb430>\n",
      "<Whisper.export.WhisperDecoderONNXFile object at 0x7f01a8009730>\n"
     ]
    }
   ],
   "source": [
    "print(wh_encoder_onnx_model_fpath)\n",
    "print(wh_decoder_onnx_model_fpath)\n",
    "print(onnx_whisper_encoder)\n",
    "print(onnx_whisper_decoder)\n",
    "#onnx_whisper_encoder = whisper_torchfile_encoder.as_onnx_model(os.path.join(wh_onnx_model_path, wh_encoder_onnx_model_fpath), force_overwrite=False)\n",
    "#onnx_whisper_decoder = whisper_torchfile_decoder.as_onnx_model(os.path.join(wh_onnx_model_path, wh_decoder_onnx_model_fpath), force_overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51a2422-c55d-4d02-85f8-4e2f659e0122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5da0a58-fbc1-41ce-be96-358cdca01f9a",
   "metadata": {},
   "source": [
    "# Whisper Tensorrt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a0bfb51e-84cc-42cd-87ea-20a9195e4511",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "from Whisper.trt import WhisperTRTEncoder, WhisperTRTDecoder, TRTHFRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8b9cf599-1da1-45d1-9caf-13632ac43b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profile().add('input_ids', min=(1, 1), opt=(1, 224), max=(1, 448)).add('encoder_hidden_states', min=(1, 1, 1280), opt=(1, 1500, 1280), max=(1, 1500, 1280))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c11bc6fa-1441-4b11-b605-bbcfd40c3502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09/06/2023-10:20:44] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n",
      "[09/06/2023-10:20:50] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n",
      "[09/06/2023-10:20:51] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n",
      "[09/06/2023-10:20:53] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n"
     ]
    }
   ],
   "source": [
    "# Initialize TensorRT engines\n",
    "trt_config = AutoConfig.from_pretrained(Whisper_VARIANT, use_cache = metadata.other.kv_cache)\n",
    "\n",
    "# FP32\n",
    "whisper_trt_encoder = WhisperTRTEncoder(whisper_trt_encoder_engine, metadata, trt_config, batch_size=batch_size)\n",
    "whisper_trt_decoder = WhisperTRTDecoder(whisper_trt_decoder_engine, metadata, trt_config, batch_size=batch_size, num_beams=num_beams)\n",
    "\n",
    "# FP16\n",
    "whisper_trt_encoder_fp16 = WhisperTRTEncoder(whisper_trt_encoder_engine_fp16, metadata_fp16, trt_config, batch_size=batch_size)\n",
    "whisper_trt_decoder_fp16 = WhisperTRTDecoder(whisper_trt_decoder_engine_fp16, metadata_fp16, trt_config, batch_size=batch_size, num_beams=num_beams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4e686e87-0318-4dc1-8495-d8002dc91ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetworkMetadata(variant='openai/whisper-large-v2', precision=Precision(fp16=True), other=WhisperMetadata(kv_cache=False))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9877bd13-1123-4a81-b0fe-5c7c3887038f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 574 ms, sys: 0 ns, total: 574 ms\n",
      "Wall time: 574 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.18660088896285743"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "encoder_last_hidden_state, encoder_trt_time = w_encoder_inference(\n",
    "    whisper_trt_encoder, input_features, TimingProfile(iterations=10, number=1, warmup=1, duration=0, percentile=[50,99])\n",
    ")\n",
    "encoder_e2e_median_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2a3749-bb79-4899-ab66-ce62c9edf2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "98088717-bcf6-470f-9c8b-1f9d0564e321",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder_last_hidden_states = whisper_trt_encoder(input_features=inputs['input_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "df023f79-959c-4838-afef-9fe885d979e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1e+03 ns, total: 6 µs\n",
      "Wall time: 11 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3556, -0.4579, -0.3098,  ..., -3.4154, -0.5449,  0.0765],\n",
       "         [ 0.0392, -0.2633,  0.2807,  ..., -3.0624, -0.5296,  0.1974],\n",
       "         [ 0.7705, -0.2222,  0.6846,  ..., -2.1927, -0.2830, -0.0171],\n",
       "         ...,\n",
       "         [ 0.5561,  0.1907, -0.0890,  ..., -0.9821, -0.1759, -0.6618],\n",
       "         [ 0.2950,  0.3261, -0.5257,  ..., -0.5850, -0.5901, -0.5439],\n",
       "         [-0.0440,  0.6661, -0.8131,  ..., -0.1867, -0.7592, -0.5468]]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "whisper_trt_encoder_fp16(input_features=inputs['input_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "475aa1df-d002-4266-89ea-1c4e9e1e7341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 10.7 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3556, -0.4579, -0.3098,  ..., -3.4154, -0.5449,  0.0765],\n",
       "         [ 0.0392, -0.2633,  0.2807,  ..., -3.0624, -0.5296,  0.1974],\n",
       "         [ 0.7705, -0.2222,  0.6846,  ..., -2.1927, -0.2830, -0.0171],\n",
       "         ...,\n",
       "         [ 0.5561,  0.1907, -0.0890,  ..., -0.9821, -0.1759, -0.6618],\n",
       "         [ 0.2950,  0.3261, -0.5257,  ..., -0.5850, -0.5901, -0.5439],\n",
       "         [-0.0440,  0.6661, -0.8131,  ..., -0.1867, -0.7592, -0.5468]]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "encoder_last_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aeaef90f-c4d3-4b9c-8295-d0e206c4b486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2115e+00, -7.7491e-01, -1.2609e+00,  ..., -3.0477e+00,\n",
       "          -1.3879e-01,  4.1334e-01],\n",
       "         [-1.0031e+00,  4.8575e-01, -3.9980e-01,  ..., -2.9799e+00,\n",
       "           1.4637e-01, -1.0124e-01],\n",
       "         [-9.0454e-01,  6.1162e-01, -3.8161e-01,  ..., -3.1192e+00,\n",
       "          -5.3057e-02,  2.5831e-02],\n",
       "         ...,\n",
       "         [-8.0957e-04, -8.1212e-03, -1.0276e-02,  ...,  4.6533e-03,\n",
       "          -4.0645e-03, -1.0909e-02],\n",
       "         [-2.8883e-03, -5.0357e-03, -1.2229e-02,  ...,  4.9758e-03,\n",
       "          -3.9479e-03, -1.0991e-02],\n",
       "         [-5.3624e-03,  2.5027e-03, -1.0828e-02,  ...,  4.0317e-03,\n",
       "           3.3815e-04, -1.2044e-02]]], device='cuda:0',\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whisper_torch_encoder(input_features=input_features.cuda().float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "477a9c85-dc6f-4162-b9a5-b0ba3c66db23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TorchModule(\n",
       "  (decoder): WhisperDecoder(\n",
       "    (embed_tokens): Embedding(51865, 1280, padding_idx=50257)\n",
       "    (embed_positions): WhisperPositionalEmbedding(448, 1280)\n",
       "    (layers): ModuleList(\n",
       "      (0): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (12): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (13): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (14): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (15): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (16): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (17): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (18): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (19): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (20): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (21): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (22): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (23): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (24): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (25): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (26): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (27): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (28): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (29): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (30): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (31): WhisperDecoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1280, out_features=51865, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whisper_torch_decoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cf5c37f4-4294-40da-8f05-c7231011b12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_last_hidden_state = whisper_torch_encoder(input_features=input_features.cuda().float())\n",
    "decoder_output_greedy = whisper_torch_decoder.greedy_search(\n",
    "    input_ids=decoder_input_ids.cuda(),\n",
    "    encoder_hidden_states=encoder_last_hidden_state.cuda(),\n",
    "    stopping_criteria=stopping_criteria,\n",
    "    logits_processor=logits_processor,\n",
    "    use_cache=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2ee33f99-e792-4049-9772-591d5473d99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|startoftranscript|><|en|><|transcribe|><|notimestamps|> Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.<|endoftext|>'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.decode(decoder_output_greedy[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "96c68a3d-9095-4d1b-941d-488447980196",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_ids = torch.full(\n",
    "    (batch_size, 1),\n",
    "    WhisperModelTRTConfig.DECODER_START_TOKEN_ID,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fd3a252c-75af-4d69-9833-84237f57ae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_last_hidden_state = whisper_trt_encoder(input_features=input_features.cuda().float())\n",
    "\n",
    "decoder_output = whisper_trt_decoder.greedy_search(\n",
    "                input_ids=decoder_input_ids.cuda(),\n",
    "                encoder_hidden_states=encoder_last_hidden_states.cuda(),\n",
    "                stopping_criteria=stopping_criteria,\n",
    "                logits_processor=logits_processor,\n",
    "                use_cache=metadata_fp16.other.kv_cache,\n",
    "                use_cuda=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41d9572-b7fb-475d-b117-d134d88e2ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2f91e494-6256-4e5a-ba03-d26332f2fd02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|startoftranscript|><|en|><|transcribe|><|notimestamps|> you<|endoftext|>'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(decoder_output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91798bb7-12fc-4eb6-803b-31e747a83a0b",
   "metadata": {},
   "source": [
    "### End-to-End TensorRT Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3a214df2-cf28-444f-a68a-351aba8c9b5f",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers.generation_logits_process import (\n",
    "    LogitsProcessorList,\n",
    "    SuppressTokensAtBeginLogitsProcessor,\n",
    "    SuppressTokensLogitsProcessor,\n",
    "    ForceTokensLogitsProcessor,\n",
    ")\n",
    "\n",
    "from transformers.generation_stopping_criteria import (\n",
    "    MaxLengthCriteria,\n",
    "    StoppingCriteriaList,\n",
    ")\n",
    "from transformers.generation_beam_search import (\n",
    "    BeamSearchScorer,\n",
    ")\n",
    "\n",
    "stopping_criteria = StoppingCriteriaList([MaxLengthCriteria(max_output_len)])\n",
    "no_repeat_ngram_size = WhisperModelTRTConfig.NO_REPEAT_NGRAM_SIZE\n",
    "min_length = WhisperModelTRTConfig.MIN_OUTPUT_LENGTH[Whisper_VARIANT]\n",
    "decoder_input_ids = torch.full(\n",
    "    (batch_size, 1),\n",
    "    WhisperModelTRTConfig.DECODER_START_TOKEN_ID,\n",
    ")\n",
    "\n",
    "forced_decoder_ids=processor.get_decoder_prompt_ids(language=\"en\", task=\"transcribe\", no_timestamps=True)\n",
    "\n",
    "stopping_criteria = StoppingCriteriaList([MaxLengthCriteria(whisper_model.config.max_length)])\n",
    "no_repeat_ngram_size = WhisperModelTRTConfig.NO_REPEAT_NGRAM_SIZE\n",
    "logits_processor = LogitsProcessorList(\n",
    "    [\n",
    "        SuppressTokensLogitsProcessor(WhisperModelTRTConfig.SUPPRESS_TOKENS),\n",
    "        SuppressTokensAtBeginLogitsProcessor(\n",
    "            WhisperModelTRTConfig.BEGIN_SUPPRESS_TOKENS, decoder_input_ids.shape[-1]\n",
    "        ),\n",
    "        ForceTokensLogitsProcessor(forced_decoder_ids),\n",
    "    ]\n",
    ")  # by checking HuggingFace's generate() implementation carefully, the default logits processor for BART has no_repeat_ngram_size = 3 and forced_eos_token_id = 2. In this way we can get identical results with raw HuggingFace\n",
    "\n",
    "encoder_outputs.last_hidden_state = encoder_outputs.last_hidden_state.cpu()\n",
    "if num_beams > 1:\n",
    "    decoder_input_ids = expand_inputs_for_beam_search(decoder_input_ids, expand_size=num_beams)\n",
    "    \n",
    "# FP32\n",
    "def e2e_trt():\n",
    "    with torch.no_grad():\n",
    "        encoder_last_hidden_states = whisper_trt_encoder(input_features=input_features)\n",
    "        \n",
    "        if num_beams > 1:\n",
    "            # prepare input for beam search\n",
    "            encoder_last_hidden_states = expand_inputs_for_beam_search(encoder_last_hidden_states, expand_size=num_beams)\n",
    "\n",
    "            # beam scorer must be reset before each beam search run, otherwise beam search will be skipped due to scorer cache\n",
    "            beam_scorer = BeamSearchScorer(\n",
    "                batch_size=batch_size,\n",
    "                num_beams=num_beams,\n",
    "                device=\"cuda:1\",\n",
    "                do_early_stopping=True,\n",
    "            )\n",
    "        \n",
    "        whisper_trt_decoder.set_encoder_hidden_states_for_inference_cycle(encoder_last_hidden_states)\n",
    "        \n",
    "        if num_beams == 1:\n",
    "            decoder_output = whisper_trt_decoder.greedy_search(\n",
    "                input_ids=decoder_input_ids.cuda(),\n",
    "                encoder_hidden_states=encoder_outputs.last_hidden_state.cuda(1),\n",
    "                stopping_criteria=stopping_criteria,\n",
    "                logits_processor=logits_processor,\n",
    "                use_cache=metadata.other.kv_cache,\n",
    "                use_cuda=True\n",
    "            )\n",
    "        else:\n",
    "            decoder_output = whisper_trt_decoder.beam_search(\n",
    "                input_ids=decoder_input_ids.cuda(),\n",
    "                beam_scorer=beam_scorer,\n",
    "                encoder_hidden_states=encoder_last_hidden_states,\n",
    "                stopping_criteria=stopping_criteria,\n",
    "                logits_processor=logits_processor,\n",
    "                use_cache=metadata.other.kv_cache,\n",
    "                use_cuda=True\n",
    "            )\n",
    "    return decoder_output\n",
    "\n",
    "output_ids = e2e_trt()\n",
    "outputs_trt = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "trt_time = measure_python_inference_code(e2e_trt, timing_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ea322cb7-ca33-4811-86bb-4002e2e03534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP16\n",
    "def e2e_trt_fp16():\n",
    "    with torch.no_grad():\n",
    "        encoder_last_hidden_states = whisper_trt_encoder_fp16(input_features=input_features)\n",
    "        \n",
    "        if num_beams > 1:\n",
    "            # prepare input for beam search\n",
    "            encoder_last_hidden_states = expand_inputs_for_beam_search(encoder_last_hidden_states, expand_size=num_beams)\n",
    "            \n",
    "            # beam scorer must be reset before each beam search run, otherwise beam search will be skipped due to scorer cache\n",
    "            beam_scorer = BeamSearchScorer(\n",
    "                batch_size=batch_size,\n",
    "                num_beams=num_beams,\n",
    "                device=\"cuda:1\",\n",
    "                do_early_stopping=True,\n",
    "            )\n",
    "        \n",
    "        whisper_trt_decoder_fp16.set_encoder_hidden_states_for_inference_cycle(encoder_last_hidden_states) \n",
    "        \n",
    "        if num_beams == 1:\n",
    "            decoder_output = whisper_trt_decoder_fp16.greedy_search(\n",
    "                input_ids=decoder_input_ids.cuda(),\n",
    "                encoder_hidden_states=encoder_last_hidden_states,\n",
    "                stopping_criteria=stopping_criteria,\n",
    "                logits_processor=logits_processor,\n",
    "                use_cache=metadata.other.kv_cache,\n",
    "                use_cuda=True\n",
    "            )\n",
    "        else:\n",
    "            decoder_output = whisper_trt_decoder_fp16.beam_search(\n",
    "                input_ids=decoder_input_ids.cuda(),\n",
    "                beam_scorer=beam_scorer,\n",
    "                encoder_hidden_states=encoder_last_hidden_states,\n",
    "                stopping_criteria=stopping_criteria,\n",
    "                logits_processor=logits_processor,\n",
    "                use_cache=metadata.other.kv_cache,\n",
    "                use_cuda=True\n",
    "            )\n",
    "    return decoder_output\n",
    "\n",
    "output_ids_fp16 = e2e_trt_fp16()\n",
    "outputs_trt_fp16 = tokenizer.decode(output_ids_fp16[0], skip_special_tokens=True)\n",
    "trt_time_fp16 = measure_python_inference_code(e2e_trt_fp16, timing_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b0dacea5-15c1-4fbc-b848-852ea84b0d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: NVIDIA A100-SXM4-80GB\n",
      "Using engine: Whisper-large-v2-bs1\n",
      "Output identical to HF results? False\n",
      "Precision: FP32\n",
      "TRT time: [0.1209204220212996, 0.12111746391747147]\n",
      "\n",
      "Using engine: Whisper-large-v2-fp16-bs1\n",
      "Output identical to HF results? False\n",
      "Precision: FP16\n",
      "TRT time: [0.08881275996100157, 0.08901880006305873]\n"
     ]
    }
   ],
   "source": [
    "# print results and timing statistics\n",
    "print(f'Device: {torch.cuda.get_device_name()}')\n",
    "print(f\"Using engine: {metadata_string + '-' + engine_tag}\")\n",
    "print(f'Output identical to HF results? {outputs_trt == outputs_hf}')\n",
    "print(f\"Precision: FP32\")\n",
    "print(f'TRT time: {trt_time}')\n",
    "print()\n",
    "print(f\"Using engine: {metadata_string_fp16 + '-' + engine_tag}\")\n",
    "print(f'Output identical to HF results? {outputs_trt_fp16 == outputs_hf}')\n",
    "print(f\"Precision: FP16\")\n",
    "print(f'TRT time: {trt_time_fp16}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8b3e3bad-86c4-486e-aef3-4fb9da753d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 158 ms, sys: 255 µs, total: 158 ms\n",
      "Wall time: 158 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a, decoder_trt_time = w_decoder_inference(whisper_trt_decoder, expand_inputs_for_beam_search(input_ids, num_beams) if num_beams > 1 else input_ids, expand_inputs_for_beam_search(encoder_last_hidden_state, num_beams) if num_beams > 1 else encoder_last_hidden_state, timing_profile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef28764-c754-4045-915a-14909b75a27b",
   "metadata": {},
   "source": [
    "### Time Measurement of Encoder, Decoder, and Full E2E\n",
    "We will benchmark the encoder, decoder, and full end-to-end as we did for HuggingFace before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49992cf-3737-4091-a300-b3bf806e2a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d0383bc9-f02e-467a-b5c2-092850dbb162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder-decoder inference \n",
    "whisper_model.float()\n",
    "whisper_model = whisper_model.cuda(1)\n",
    "\n",
    "input_features = input_features.float().cuda(1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_ids = whisper_model.generate(input_features, max_length=max_output_len, min_length=min_output_len, num_beams=num_beams, use_cache=False)    \n",
    "    outputs = tokenizer.decode(output_ids[-1,:], skip_special_tokens=True)    \n",
    "outputs_hf = outputs\n",
    "\n",
    "# timing\n",
    "# FP32\n",
    "input_features = input_features.float().cuda(1)\n",
    "hf_nonkv_time = measure_python_inference_code(lambda: whisper_model.generate(input_features, max_length=max_output_len, min_length=min_output_len, num_beams=num_beams, use_cache=False), timing_profile)\n",
    "hf_kv_time = measure_python_inference_code(lambda: whisper_model.generate(input_features, max_length=max_output_len, min_length=min_output_len, num_beams=num_beams, use_cache=True), timing_profile)\n",
    "\n",
    "# FP16, cuda 11.4 has cublas error that will fail in both cpu or cpu model for BART\n",
    "hf_nonkv_time_fp16 = measure_python_inference_code(lambda: whisper_model.generate(input_features, max_length=max_output_len, min_length=min_output_len, num_beams=num_beams, use_cache=False), timing_profile)\n",
    "hf_kv_time_fp16 = measure_python_inference_code(lambda: whisper_model.generate(input_features, max_length=max_output_len, min_length=min_output_len, num_beams=num_beams, use_cache=True), timing_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6e9d06d2-2a0b-4f09-9c14-0249d92a46d4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder time: p50 46.94ms, p99 61.85ms\n",
      "Decoder time: p50 13.04ms, p99 14.47ms\n",
      "Full E2E time: p50 120.81ms, p99 122.05ms\n",
      "Encoder FP16 time: p50 46.89ms, p99 46.92ms\n",
      "Decoder FP16 time: p50 7.92ms, p99 8.67ms\n",
      "Full E2E FP16 time: p50 88.59ms, p99 89.33ms\n"
     ]
    }
   ],
   "source": [
    "# FP32\n",
    "encoder_last_hidden_states, encoder_trt_time = w_encoder_inference(whisper_trt_encoder, input_features, timing_profile)\n",
    "_, decoder_trt_time = w_decoder_inference(whisper_trt_decoder, expand_inputs_for_beam_search(input_ids, num_beams) if num_beams > 1 else input_ids, expand_inputs_for_beam_search(encoder_last_hidden_states, num_beams) if num_beams > 1 else encoder_last_hidden_states, timing_profile)\n",
    "\n",
    "if num_beams == 1:\n",
    "    _, full_trt_time = full_inference_greedy(\n",
    "        whisper_trt_encoder,\n",
    "        whisper_trt_decoder,\n",
    "        input_features,\n",
    "        tokenizer,\n",
    "        timing_profile,\n",
    "        max_length=max_output_len,\n",
    "        min_length=0,\n",
    "        batch_size=batch_size,\n",
    "        use_cache=metadata.other.kv_cache,\n",
    "    )\n",
    "else:\n",
    "    _, full_trt_time = full_inference_beam(\n",
    "        whisper_trt_encoder,\n",
    "        whisper_trt_decoder,\n",
    "        input_ids,\n",
    "        tokenizer,\n",
    "        timing_profile,\n",
    "        num_beams=num_beams,\n",
    "        max_length=max_output_len,\n",
    "        min_length=0,\n",
    "        batch_size=batch_size,\n",
    "        use_cache=metadata.other.kv_cache,\n",
    "        early_stopping=True,\n",
    "    )\n",
    "    \n",
    "print(f'Encoder time: {percentile_print(encoder_trt_time)}')\n",
    "print(f'Decoder time: {percentile_print(decoder_trt_time)}')\n",
    "print(f'Full E2E time: {percentile_print(full_trt_time)}')\n",
    "\n",
    "# FP16\n",
    "encoder_last_hidden_states, encoder_trt_time_fp16 = w_encoder_inference(whisper_trt_encoder_fp16, input_features, timing_profile)\n",
    "_, decoder_trt_time_fp16 = w_decoder_inference(whisper_trt_decoder_fp16, expand_inputs_for_beam_search(input_ids, num_beams) if num_beams > 1 else input_ids, expand_inputs_for_beam_search(encoder_last_hidden_states, num_beams) if num_beams > 1 else encoder_last_hidden_states, timing_profile)\n",
    "\n",
    "if num_beams == 1:\n",
    "    _, full_trt_time_fp16 = full_inference_greedy(\n",
    "        whisper_trt_encoder_fp16,\n",
    "        whisper_trt_decoder_fp16,\n",
    "        input_features,\n",
    "        tokenizer,\n",
    "        timing_profile,\n",
    "        max_length=max_output_len,\n",
    "        min_length=0,\n",
    "        batch_size=batch_size,\n",
    "        use_cache=metadata.other.kv_cache,\n",
    "    )\n",
    "else:\n",
    "    _, full_trt_time_fp16 = full_inference_beam(\n",
    "        whisper_trt_encoder_fp16,\n",
    "        whisper_trt_decoder_fp16,\n",
    "        input_ids,\n",
    "        tokenizer,\n",
    "        timing_profile,\n",
    "        num_beams=num_beams,\n",
    "        max_length=max_output_len,\n",
    "        min_length=0,\n",
    "        batch_size=batch_size,\n",
    "        use_cache=metadata.other.kv_cache,\n",
    "        early_stopping=True,\n",
    "    )\n",
    "print(f'Encoder FP16 time: {percentile_print(encoder_trt_time_fp16)}')\n",
    "print(f'Decoder FP16 time: {percentile_print(decoder_trt_time_fp16)}')\n",
    "print(f'Full E2E FP16 time: {percentile_print(full_trt_time_fp16)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3dccd523-e56f-46fe-bdb8-b93730701958",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Framework               | Precision   | Encoder p50 (ms)   | Decoder p50 (ms)   |   Full E2E p50 (ms) | Accuracy   |\n",
      "|-------------------------|-------------|--------------------|--------------------|---------------------|------------|\n",
      "| HuggingFace (w/o cache) | FP32        | -                  | -                  |             1130.56 | -          |\n",
      "| HuggingFace (w/ cache)  | FP32        | -                  | -                  |              676.55 | -          |\n",
      "| HuggingFace (w/o cache) | FP16        | -                  | -                  |             1131.42 | -          |\n",
      "| HuggingFace (w/ cache)  | FP16        | -                  | -                  |              683.25 | -          |\n",
      "| PyTorch                 | FP32        | 186.72             | 31.47              |              668.09 | True       |\n",
      "| PyTorch                 | FP16        | 46.39              | 27.84              |              536.8  | True       |\n",
      "| TensorRT                | FP32        | 46.94              | 13.04              |              120.81 | False      |\n",
      "| TensorRT                | FP16        | 46.89              | 7.92               |               88.59 | False      |\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "data = [\n",
    "    ['Framework', 'Precision', 'Encoder p50 (ms)', 'Decoder p50 (ms)', 'Full E2E p50 (ms)', 'Accuracy'],\n",
    "    ['HuggingFace (w/o cache)', 'FP32', '-', '-', f'{hf_nonkv_time[0]*1000:.2f}', '-'],\n",
    "    ['HuggingFace (w/ cache)', 'FP32', '-', '-', f'{hf_kv_time[0]*1000:.2f}', '-'],\n",
    "    ['HuggingFace (w/o cache)', 'FP16', '-', '-', f'{hf_nonkv_time_fp16[0]*1000:.2f}', '-'],\n",
    "    ['HuggingFace (w/ cache)', 'FP16', '-', '-', f'{hf_kv_time_fp16[0]*1000:.2f}', '-'],\n",
    "    ['PyTorch', 'FP32', f'{encoder_pytorch_time[0]*1000:.2f}', f'{decoder_pytorch_time[0]*1000:.2f}', f'{full_pytorch_time[0]*1000:.2f}', outputs_pytorch == outputs_hf],\n",
    "    ['PyTorch', 'FP16', f'{encoder_pytorch_time_fp16[0]*1000:.2f}', f'{decoder_pytorch_time_fp16[0]*1000:.2f}', f'{full_pytorch_time_fp16[0]*1000:.2f}', outputs_pytorch_fp16 == outputs_hf],\n",
    "    ['TensorRT', 'FP32', f'{encoder_trt_time[0]*1000:.2f}', f'{decoder_trt_time[0]*1000:.2f}', f'{full_trt_time[0]*1000:.2f}', outputs_trt == outputs_hf],\n",
    "    ['TensorRT', 'FP16', f'{encoder_trt_time_fp16[0]*1000:.2f}', f'{decoder_trt_time_fp16[0]*1000:.2f}', f'{full_trt_time_fp16[0]*1000:.2f}', outputs_trt_fp16 == outputs_hf],\n",
    "]\n",
    "\n",
    "print(tabulate(data, headers='firstrow', tablefmt='github'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "035448da-07b5-4623-8dd8-239435e8b1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_pytorch_fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1c41f00c-2892-445c-ab31-a7fe8b138dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "017c04bb-c3ac-4d09-ae46-c6f7bbb6ce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_last_hidden_states, encoder_trt_time_fp16 = w_encoder_inference(whisper_trt_encoder_fp16, input_features, timing_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d61b675-3b97-4084-8dd9-8dea35098a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009a3372-3e53-4711-ba9b-08bfea6333f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
